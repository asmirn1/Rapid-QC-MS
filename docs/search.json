[
  {
    "objectID": "user-guide.html",
    "href": "user-guide.html",
    "title": "User Guide",
    "section": "",
    "text": "This page offers brief tutorials for usage and configuration of various Rapid-QC-MS features. Be sure to use the navigation guide below – or simply Ctrl + F – to find what you’re looking for."
  },
  {
    "objectID": "user-guide.html#incorporating-metadata-for-samples",
    "href": "user-guide.html#incorporating-metadata-for-samples",
    "title": "User Guide",
    "section": "Incorporating metadata for samples",
    "text": "Incorporating metadata for samples\nTo map metadata to samples, you can create a metadata table in CSV format and fill the following columns (where applicable):\n\nFilename\nName from collaborator\nSample Name\nSpecies\nMatrix\nGrowth-Harvest Conditions\nTreatment\n\nHere is an example metadata table:\n\n\n\n\n\n\n\n\n\n\n\n\n\nFilename\nName from collaborator\nSample Name\nSpecies\nMatrix\nGrowth-Harvest Conditions\nTreatment\n\n\n\n\n\nSample_001\nA_1\nEMGO001_A_1\nHuman HEK293T\nWhole cell\nFlash Frozen\nBHB\n\n\n\nSample_002\nA_2\nEMGO001_A_2\nHuman HEK293T\nWhole cell\nFlash Frozen\nButyrate\n\n\n\nSample_003\nA_3\nEMGO001_A_3\nHuman HEK293T\nWhole cell\nFlash Frozen\nNo treatment\n\n\n\n\nIncluding a metadata table in a QC job allows metadata to be viewed in sample information cards. It also allows the intensity across samples plot to be filtered by treatments."
  },
  {
    "objectID": "user-guide.html#setting-up-chromatography-methods",
    "href": "user-guide.html#setting-up-chromatography-methods",
    "title": "User Guide",
    "section": "Setting up chromatography methods",
    "text": "Setting up chromatography methods\nThe workflow for configuring chromatography methods is simple:\n\nAdd a chromatography method\nSelect the chromatography and polarity to modify\nAdd an internal standard library\nOptional: Set a different MS-DIAL processing configuration\n\n\n3a. Add a chromatography method\nNavigate to Settings &gt; Chromatography Methods. In the Manage chromatography methods section at the top, add a new chromatography method by giving it a name and clicking Add method.\n\nIf successful, you should see your new method in the Chromatography Methods table.\n\n\n3b. Select the chromatography and polarity to modify\nInternal standards must be configured for both positive and negative mode for each chromatography method.\nLet’s start by selecting the chromatography method you created, and then selecting Positive Mode for the polarity.\n\n\n\n\n\n3c. Add an internal standard library\nNow, we can specify our internal standard library. Rapid-QC-MS accepts identification libraries in either MSP or CSV format.\nIt is important to note that MS-DIAL can only perform MS2 spectral matching using MSP libraries. If you use a CSV library, identification will be performed via m/z and RT matches.\nHere is an example internal standard library in CSV format:\n\n\n\nCommon Name\nMS1 m/z\nRT (min)\n\n\n\n\n1_Methionine_d8\n158.1085398\n7.479\n\n\n1_1_Methylnicotinamide_d3\n141.0975946\n6.217\n\n\n1_Creatinine_d3\n117.0850186\n4.908\n\n\n…\n…\n…\n\n\n1_Lysine d8\n155.1630181\n9.578\n\n\n1_Phenylalanine d8\n174.136469\n6.92\n\n\n1_Hippuric acid d5\n185.0969033\n3.011\n\n\n\nAnd here is one internal standard from a library in MSP format:\nNAME: 1_HippuricAcid_d5\nSCANNUMBER: 1229\nRETENTIONTIME: 3.011485\nPRECURSORMZ: 185.0967\nPRECURSORTYPE: [M+H]+\nIONMODE: Positive\nINTENSITY: 2.157809E+07\nISOTOPE: M + 0\nINCHIKEY:\nSMILES:\nFORMULA:\nNum Peaks: 33\n51.02318    5550\n56.94302    2599\n57.93503    32786\n...\n171.3111    3202\n181.08981   2837\n185.09656   4996\nClick the Browse Files button to browse for your MSP or CSV file, then click the Add MSP to  Positive Mode button.\n\nAfter a few seconds, your screen should look something like this.\n\nYou can confirm that the library was successfully added by scrolling up to the Chromatography Methods table and seeing the updated number of Pos (+) Standards.\nThat’s it! Now, you can select Negative Mode from the polarity dropdown and add your negative mode internal standards."
  },
  {
    "objectID": "user-guide.html#setting-up-biological-standards",
    "href": "user-guide.html#setting-up-biological-standards",
    "title": "User Guide",
    "section": "Setting up biological standards",
    "text": "Setting up biological standards\nBiological standards are used to benchmark instrument performance based on the intensity of targeted features in the biological standard samples.\nYou can configure Rapid-QC-MS to detect and process biological standards accordingly using the following guide:\n\nNavigate to Settings &gt; Chromatography Methods.\nCreate a biological standard: this requires providing a name and sequence identifier.\nSelect the chromatography method to edit: you can add libraries for different chromatography methods and polarities.\nAdd an MSP library: this MSP library will be used for the biological standard / chromatography combination you select.\n\nThe sequence identifier is simply the text string that identifies biological standards in your acquisition sequences. For example, if “bac_sup” is the identifier for a biological standard, then any sample with “bac_sup” in its filename will be processed as a biological standard.\n\n\n\nTargeted feature libraries must be in MSP format. Here is an example of one targeted feature in an MSP library.\nNAME: Hippuric acid d5\nSCANNUMBER: 1229\nRETENTIONTIME: 3.011485\nPRECURSORMZ: 185.0967\nPRECURSORTYPE: [M+H]+\nIONMODE: Positive\nINTENSITY: 2.157809E+07\nISOTOPE: M + 0\nINCHIKEY:\nSMILES:\nFORMULA:\nNum Peaks: 33\n51.02318    5550\n56.94302    2599\n57.93503    32786\n...\n171.3111    3202\n181.08981   2837\n185.09656   4996\nYou can also specify different processing configurations for biological standards by using the MS-DIAL processing configuration dropdown. These configurations can be created and saved in Settings &gt; MS-DIAL Configurations."
  },
  {
    "objectID": "user-guide.html#configuring-qc-parameters",
    "href": "user-guide.html#configuring-qc-parameters",
    "title": "User Guide",
    "section": "Configuring QC parameters",
    "text": "Configuring QC parameters\nNavigate to Settings &gt; QC Configurations to define your QC criteria. Briefly, these are:\n\nIntensity dropouts cutoff: the minimum number of missing internal standards in a sample to constitute a QC fail\nRT shift from library value cutoff: the minimum retention time shift from the expected library value to constitute a QC fail\nRT shift from in-run average cutoff: the minimum retention time shift from the average RT during the course of the run to constitute a QC fail\nm/z shift from library value cutoff: the minimum m/z shift from the expected library value to constitute a QC fail\n\n\nRapid-QC-MS stores individual parameters in configurations, so that you can configure a specific configuration to fit each chromatography method. Every installation comes preloaded with a “Default” configuration containing recommended parameters.\n\n\n\nYou can specify these parameters however you’d like, and enable / disable them as needed. To revert a configuration back to the default recommended settings, simply click the Reset default settings button.\nOnce you’re done, don’t forget to click Save changes!"
  },
  {
    "objectID": "user-guide.html#configuring-ms-dial-processing-parameters",
    "href": "user-guide.html#configuring-ms-dial-processing-parameters",
    "title": "User Guide",
    "section": "Configuring MS-DIAL processing parameters",
    "text": "Configuring MS-DIAL processing parameters\nMS-DIAL is the processing software used to quantify internal standards in samples and targeted features in biological standards.\nRapid-QC-MS stores a set of MS-DIAL parameters in configurations, so that you can configure a specific configuration to fit each chromatography method. Every installation comes preloaded with a “Default” configuration containing recommended parameters.\n\n\n\nYou can create a new configuration using the Add new MS-DIAL configuration text field. Then, select it from the dropdown to edit its parameters. Once you’re done, the MS-DIAL configuration can be applied to chromatography methods and biological standards.\nA wide range of parameters are available for modification to fit the user’s needs:\n\nRetention time begin\nRetention time end\nMass range begin\nMass range end\nMS1 centroid tolerance\nMS2 centroid tolerance\nSmoothing method\nSmoothing level\nMass slice width\nMinimum peak width: Peak width threshold\nMinimum peak height: Peak height threshold\nPost-identification retention time tolerance\nPost-identification accurate MS1 tolerance\nPost-identification similarity score cutoff\nAlignment retention time tolerance\nAlignment MS1 tolerance\nAlignment retention time factor\nAlignment MS1 factor\nPeak count filter\nQC at least filter\n\nFor more details on MS-DIAL parameters, see the documentation here.\nOnce you’re done editing, don’t forget to click Save changes! You can now apply this processing configuration to your chromatography methods and biological standards."
  },
  {
    "objectID": "user-guide.html#setting-up-google-drive-sync",
    "href": "user-guide.html#setting-up-google-drive-sync",
    "title": "User Guide",
    "section": "Setting up Google Drive sync",
    "text": "Setting up Google Drive sync\nTo allow access to your workspace from any device, you must first create a project in the Google Cloud Console and generate an OAuth Client ID for your installation of Rapid-QC-MS.\nThese actions only need to be performed once. Upon completion, any shared user will be able to use the Client ID and Client Secret to sign in to your workspace.\n\n1. Create a project in the Google Cloud Console\nIn case the above steps are too difficult to follow, below is a detailed walkthrough of the process with screenshots.\nNavigate to the Google Cloud Console. The landing page should look something like this:\n\n\n\nChoose Create or select a project, then click New Project.\nName the project whatever you like, ideally something you’ll recogize, and click Create. If your google account belongs to an organization, this screen might look a little different but should function the same.\n\n\n\nFrom the sidebar, navigate to Enabled APIs and services and click Enable APIs and Services.\n\n\n\n\nNext, search for “Gmail API”, select it, and click the Enable button and wait for google to process your request. Once it’s enabled, go back and repeat the process for “Google Drive API”\n\nIf all went well, both API’s should be visible on the API & Services package\n\n\n\n2. Configure the OAuth consent screen\nFrom the sidebar, navigate to APIs & Services &gt; OAuth consent screen.\nFor user type, choose Internal and click Create. Fill in the following:\n\nApp name: Rapid-QC-MS\nUser support email: [email]\nDeveloper contact information: [email]\n\nOnce you’re done, click Save and Continue.\nOn the next screen, select Add or Remove Scopes. Scroll down to the Manually add scopes section and paste in the following:\nhttps://www.googleapis.com/auth/drive\nhttps://www.googleapis.com/auth/gmail.send\nhttps://www.googleapis.com/auth/userinfo.email\n\n\n\nClick Add to Table. Then click Update. Then click Save and Continue.\n\n\n3. Generate the OAuth Client ID\nFrom the sidebar, navigate to APIs & Services &gt; Credentials.\nClick the Create Credentials button and select OAuth client ID.\n\n\n\nFor application type, choose Desktop application. Name the application Rapid-QC-MS.\nOnce you’re done, click Create. A dialog window will appear, providing your client ID and client secret.\n\n\n\nThat’s it – you’re all set! Copy these and save them somewhere accessible. If you’re here from the Quickstart guide, click here to head back and use these credentials to set up or sign in to your workspace."
  },
  {
    "objectID": "user-guide.html#adding-instruments-to-workspace",
    "href": "user-guide.html#adding-instruments-to-workspace",
    "title": "User Guide",
    "section": "Adding instruments to workspace",
    "text": "Adding instruments to workspace\nTo add an instrument to an existing Rapid-QC-MS workspace, perform the following steps:\n\nInstall Rapid-QC-MS on your instrument computer\nLaunch the app by entering ms_autoqc in a terminal window\nSelect the I’m setting up Rapid-QC-MS on a new instrument tab\nGive your instrument a name and specify the vendor\nEnter your client ID and client secret, then click Sign in to Google Drive\nComplete the authentication flow\nOnce you’re done, Rapid-QC-MS will alert you that your workspace was found\nClick Complete setup and you’re all set!\n\n\nImportant: Currently, it is not possible to add an instrument to an existing workspace after setup. If you want to add your instrument to an existing workspace, it must be done during setup immediately after a fresh install."
  },
  {
    "objectID": "user-guide.html#granting-revoking-workspace-access",
    "href": "user-guide.html#granting-revoking-workspace-access",
    "title": "User Guide",
    "section": "Granting / revoking workspace access",
    "text": "Granting / revoking workspace access\nYou can grant and revoke access to your Rapid-QC-MS workspace from Settings &gt; General.\nUnder Manage workspace access, add the email addresses for Google accounts you’d like to share your workspace with."
  },
  {
    "objectID": "user-guide.html#signing-in-to-workspace-from-external-devices",
    "href": "user-guide.html#signing-in-to-workspace-from-external-devices",
    "title": "User Guide",
    "section": "Signing in to workspace from external devices",
    "text": "Signing in to workspace from external devices\nYou can use your generated client ID and client secret to log in to your workspace from any device.\n\nInstall Rapid-QC-MS on your device\nLaunch the app by entering ms_autoqc in a terminal window\nSelect the I’m signing in to an existing Rapid-QC-MS workspace tab\nEnter your client ID and client secret, then click Sign in to Google Drive\nComplete the authentication flow\nClick Sign in to Rapid-QC-MS workspace and you’re all set!\n\nImportant: Do NOT check the I’m signing in from an instrument computer checkbox – it is intended for signing in to the workspace after reinstalls on the instrument computer.\n\nImportant note: To allow your team members to sign in to the workspace using their Google account, you must first grant them access in Settings &gt; General."
  },
  {
    "objectID": "user-guide.html#setting-up-slack-notifications",
    "href": "user-guide.html#setting-up-slack-notifications",
    "title": "User Guide",
    "section": "Setting up Slack notifications",
    "text": "Setting up Slack notifications\nTo set up Slack notifications, you must create your own Slack bot, generate an OAuth token for it, and give that token to Rapid-QC-MS in Settings &gt; General.\nYou only need to do this once! After that, Rapid-QC-MS will use your token to alert you about QC warnings and QC fails.\n\n1. Create your Slack bot\nNavigate to the Slack API console and click the Create New App button.\nChoose to create your app From Scratch. Fill in the App Name and your Slack workspace, then click Create App.\n\n\n\n\n\n2. Generate an OAuth token\nFrom the sidebar, navigate to Features &gt; OAuth & Permissions.\nScroll down to the Scopes section. For Bot Token Scopes, add the following OAuth scopes:\nchat:write\nchat:write.public\nincoming-webhook\n\n\n\nNow, scroll back up to the OAuth Tokens for Your Workspace section and click Install to Workspace. Once that’s done, you will have generated your Bot User OAuth Token!\n\n\n3. Give token to Rapid-QC-MS\nIn Rapid-QC-MS, navigate to Settings &gt; General and paste the token you generated in the Slack API client credentials field. Click Save bot token.\nNow, enter the name of the channel you’d like Rapid-QC-MS to post messages to. Once you’re done, toggle Enable notifications.\n\n\n\nLastly, you need to invite the bot to the channel. The easiest way of doing this is to just @botname in the channel and slack will ask if you want to invite it."
  },
  {
    "objectID": "user-guide.html#setting-up-email-notifications",
    "href": "user-guide.html#setting-up-email-notifications",
    "title": "User Guide",
    "section": "Setting up email notifications",
    "text": "Setting up email notifications\nTo set up email notifications, you must first enable Google Drive sync.\nOnce that’s done, all you have to do is navigate to Settings &gt; General and register email addresses for notifications!"
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "Overview",
    "section": "",
    "text": "Many different things can go wrong during an LC-MS instrument run, leading to unusable data. That’s why it is crucial to stop a run and troubleshoot if something is wrong.\nMany metabolomics labs have various quality control measures in place for every sample preparation protocol, such as internal standards or biological “benchmark” standards. However, analyzing the data from these QC markers can be tedious and time-consuming.\nThis section describes the various features of Rapid-QC-MS, and how they can help inform on the quality of your untargeted metabolomics data in a time-efficient manner."
  },
  {
    "objectID": "overview.html#retention-time-across-samples",
    "href": "overview.html#retention-time-across-samples",
    "title": "Overview",
    "section": "Retention time across samples",
    "text": "Retention time across samples\nPlotting retention time values for a given internal standard gives insight into retention time shifts, which can indicate any of the following:\n\nIncorrect mobile phase concentration\nChanges in flow rate\nChanges in column temperature\nFaulty / damaged column\n\nThe retention time vs. sample plot provides an at-a-glance view into trends or issues with chromatography. The user can hover over each point to display relevant metadata for a sample, zoom or pan over the graph, and even grab a screenshot for easy sharing with teammates.\nTry it out yourself below!\n\n\n\n                                                \n\n\nAdditionally, the user can select an internal standard using the dropdown, or seek through them using the previous / next buttons. Rapid-QC-MS provides global filters for polarity and sample type in the sidebar as well."
  },
  {
    "objectID": "overview.html#intensity-across-samples",
    "href": "overview.html#intensity-across-samples",
    "title": "Overview",
    "section": "Intensity across samples",
    "text": "Intensity across samples\nPlotting intensity (peak height) values can give insight into sample preparation and ionization variability. Low internal standard intensities could indicate:\n\nBad injection\nError in sample preparation\nInstrument performance (sample not ionizing correctly)\n\nRapid-QC-MS allows you to filter the intensity vs. sample plot by samples, pools, or blanks using the plot filter in the sidebar. You can also scroll through the plot using the plot scroll bar at the bottom."
  },
  {
    "objectID": "overview.html#delta-mz-across-samples",
    "href": "overview.html#delta-mz-across-samples",
    "title": "Overview",
    "section": "Delta m/z across samples",
    "text": "Delta m/z across samples\nThe mass accuracy of a mass spectrometer can be evaluated by plotting delta m/z values, which can also provide insight into the instrument’s overall performance.\nWhile it may not always be immediately apparent if there are problems with the mass accuracy, the delta m/z vs. samples plot ensures the reliability of an experiment’s results."
  },
  {
    "objectID": "overview.html#system-suitability-benchmarks",
    "href": "overview.html#system-suitability-benchmarks",
    "title": "Overview",
    "section": "System suitability benchmarks",
    "text": "System suitability benchmarks\nRapid-QC-MS allows you to benchmark your LC-MS instrument using biological standards. Track the performance of your instrument’s ionization efficiency across various mass ranges and sample matrices.\n\nThe m/z across RT plot of targeted features in your biological standard provides an at-a-glance view of which features are performing well or poorly compared to previous instrument runs.\nThe plot features a colorscale for the percent change of each feature (for a selected biological standard) from its average intensity.\n\nBlue represents positive percent change and red represents negative percent change, meaning you can breathe easy for plots with lots of blue, or start investigating if you see lots of red.\nClicking any of the features updates the feature intensity across instrument runs plot, which provides a firsthand view of whether your instrument’s performance has declined or improved over time.\n\nSetting up biological standards is easy. You can add targeted feature libraries for biological standards in different chromatography methods and polarities in Settings &gt; Biological Standards. Visit the User Guide to see how."
  },
  {
    "objectID": "overview.html#sample-information-card",
    "href": "overview.html#sample-information-card",
    "title": "Overview",
    "section": "Sample information card",
    "text": "Sample information card\nTo investigate a sample more closely, you can select one from the sample table (or click a marker on the plot!) and the sample information card will open.\nThis card conveniently aggregates sample information from the acquisition sequence, sample metadata, processed data, and QC results in one place."
  },
  {
    "objectID": "overview.html#new-qc-job-setup",
    "href": "overview.html#new-qc-job-setup",
    "title": "Overview",
    "section": "New QC job setup",
    "text": "New QC job setup\nQC jobs point Rapid-QC-MS to monitor active instrument runs or process data files in bulk. Setting up a new job was designed to be as fast and easy as possible.\n\nTo QC an instrument run or acquired data files, the user just needs to enter:\n\nRun ID: a name for the instrument run / QC job\nChromatography: the chromatography method for this instrument run\nBiological standard(s) (optional): any biological standards included in the run\nAcquisition sequence file: the acquisition sequence, in CSV format\nSample metadata file (optional): metadata for samples, in CSV format\nData file directory: the folder in which data files will be acquired (or will exist)\n\nThe form then validates resources and gives the user intelligent feedback.\n\n\n\nOnce the user has chosen whether the job is for an active or completed instrument run, the new job can be executed."
  },
  {
    "objectID": "overview.html#slack-email-notifications",
    "href": "overview.html#slack-email-notifications",
    "title": "Overview",
    "section": "Slack / email notifications",
    "text": "Slack / email notifications\nBe in the know without sitting in front of your instrument. Get live notifications during active instrument runs – via Slack or email – so that you can deal with QC warnings and fails in a timely fashion."
  },
  {
    "objectID": "overview.html#google-drive-sync",
    "href": "overview.html#google-drive-sync",
    "title": "Overview",
    "section": "Google Drive sync",
    "text": "Google Drive sync\nIf the user opts to set up and enable Google Drive sync with their Google account, the Rapid-QC-MS workspace can be securely accessed from any device.\nAll data is stored and synced on the user’s Google Drive account, allowing instrument runs to be monitored from home and QC results to be accessed in realtime by all relevant stakeholders at the same time."
  },
  {
    "objectID": "overview.html#workspace",
    "href": "overview.html#workspace",
    "title": "Overview",
    "section": "Workspace",
    "text": "Workspace\nIn Settings &gt; General, the user is able to:\n\nEnable Google Drive cloud sync\nManage workspace access among users\nRegister a Slack bot for Slack notifications\nRegister addresses for email notifications"
  },
  {
    "objectID": "overview.html#internal-standards",
    "href": "overview.html#internal-standards",
    "title": "Overview",
    "section": "Internal standards",
    "text": "Internal standards\nIn Settings &gt; Chromatography Methods, the user is able to:\n\nAdd / delete chromatography methods\nAdd internal standard libraries for each chromatography–polarity combination\nSet a custom processing configuration for each chromatography method"
  },
  {
    "objectID": "overview.html#biological-standards",
    "href": "overview.html#biological-standards",
    "title": "Overview",
    "section": "Biological standards",
    "text": "Biological standards\nIn Settings &gt; Biological Standards, the user is able to:\n\nAdd / delete biological standards with sequence identifiers\nAdd metabolite libraries for each biological standard–chromatography–polarity combination\nSet custom processing configuration for each biological standard–chromatography combination"
  },
  {
    "objectID": "overview.html#qc-configurations",
    "href": "overview.html#qc-configurations",
    "title": "Overview",
    "section": "QC configurations",
    "text": "QC configurations\nIn Settings &gt; QC Configurations, the user is able to:\n\nAdd / delete QC configurations\nSet cutoff for intensity dropouts\nSet cutoff for RT shift from library value\nSet cutoff for RT shift from in-run average\nSet cutoff for m/z drift from library value"
  },
  {
    "objectID": "overview.html#ms-dial-configurations",
    "href": "overview.html#ms-dial-configurations",
    "title": "Overview",
    "section": "MS-DIAL configurations",
    "text": "MS-DIAL configurations\nIn Settings &gt; MS-DIAL Configurations, the user is able to:\n\nAdd / delete MS-DIAL configurations\nSet data collection parameters\nSet centroid parameters\nSet peak detection parameters\nSet identification parameters\nSet alignment parameters"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rapid-QC-MS",
    "section": "",
    "text": "Rapid-QC-MS is an all-in-one solution for automated quality control of liquid chromatography-mass spectrometry (LC-MS) instrument runs, both during and after data acquisition.\nIt offers a fast, straightforward approach to ensure collection of high-quality data, allowing for less time investigating raw data and more time conducting experiments.\n \nDeveloped at the Mass Spectrometry Platform of CZ Biohub San Francisco, Rapid-QC-MS provides a host of key features to streamline untargeted metabolomics research, such as:\n\nAutomated and user-defined quality control checks during instrument runs\nRealtime updates on QC fails in the form of Slack or email notifications\nInteractive data visualization of internal standard retention time, m/z, and intensity across samples\nGoogle Drive cloud sync and secure, Google-authenticated access to QC results from any device\n\n\nRequirements\nRapid-QC-MS was designed to run on Windows platforms because of its dependency on MSConvert for vendor format data conversion and MS-DIAL for data processing and identification. However, MacOS users can still use Rapid-QC-MS to monitor / view their instrument run data.\nIn addition, Rapid-QC-MS requires Python 3.8+ and various Python packages, including:\n\nPandas\nSQLAlchemy\nPlotly Dash\nBootstrap\nWatchdog\nGoogle API\nSlack API\n\nThese are installed automatically during setup.\nNote: Installation of Python and various Python packages on MS instrument computers comes at no risk. For extra security and peace of mind, you can opt to install Rapid-QC-MS in a virtual environment. To learn more, please read the installation guide.\n\n\nInstallation and usage\nInstalling Rapid-QC-MS is easy. Simply open your Terminal or Command Prompt and enter:\npy -m pip install rapidqcms\nPython dependencies are installed automatically, but dependencies such as MSConvert and MS-DIAL will need to be installed manually.\nTo start Rapid-QC-MS, simply enter:\nrapidqcms\nYou can also opt to download and install Rapid-QC-MS manually, or in a virtual environment if you prefer. Check out the installation guide for more details.\n\n\nSupported instrument vendors\nRapid-QC-MS was designed to be a universal, open-source solution for data quality control. Because MSConvert converts raw acquired data into open mzML format before routing it to the data processing pipeline, the package will work seamlessly with data of all vendor formats.\nHowever, Rapid-QC-MS has only been tested extensively on Thermo Fisher mass spectrometers, Thermo acquisition sequences, and Thermo RAW files. As such, it is expected that there may be bugs and issues with processing data of other vendor formats.\nIf you encounter a bug, please report it by opening an issue on GitHub.\nWe are open to collaboration! If you would like to help us develop support for Agilent, Bruker, Sciex, or Waters acquisition sequences and data files, please send an email to brian.defelice@czbiohub.org."
  },
  {
    "objectID": "documentation.html",
    "href": "documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "AcquisitionListener\nDefines classes and functions for monitoring data acquisition paths and processing data files.\n\n\nAutoQCProcessing\nModular pipeline for processing data files, performing quality control, and writing QC results to the database.\n\n\nDashWebApp\nConstructs the web app using Dash components for layout and Dash callbacks for event handling.\n\n\nDatabaseFunctions\nProvides highly-abstracted API for reading from and writing to instrument and settings databases.\n\n\nPlotGeneration\nParses QC results from the database into the browser cache to generate fast and responsive Plotly graphs.\n\n\nSlackNotifications\nDefines functions for sending messages to Slack channels using a Slack bot."
  },
  {
    "objectID": "design.html",
    "href": "design.html",
    "title": "System Design",
    "section": "",
    "text": "This section details the backend data infrastructure and data processing pipeline packaged into MS-AutoQC, as well as some of the structure and logic of the Dash callbacks that serve the frontend app interface.\nIf you have any questions, concerns, or suggestions about the design of MS-AutoQC, please don’t hesitate to contact us!\n\nDesign pattern\nMS-AutoQC was designed with flexibility and scalability in mind. The project follows the MVC (Model-View-Controller) design pattern. The separation of concerns allows multiple developers to manage and make changes to the frontend and backend easily.\n\n\nFrontend\nThe frontend consists of a Dash app, which launches on startup and can be used from the browser. Dash is a powerful, open-source Python framework (built atop React, Plotly, and Flask) for building web applications.\nIn summary, components make up a user interface, and callbacks map inputs from one component to outputs of another. There is very little boilerplate code required to get started, and the library is extremely well-documented by the developers and community.\n\n\nBackend\nThe backend is organized into five different files:\n\nAcquisitionListener defines classes and functions for monitoring data acquisition paths and processing data files.\nDatabaseFunctions provides highly-abstracted API for reading from and writing to databases.\nAutoQCProcessing is a modular pipeline for processing data files, performing QC checks, and writing QC results to the database.\nSlackNotifications defines functions for controlling the Slack bot.\nPlotGeneration parses QC results from the database into the browser cache to generate Plotly graphs.\n\nThe complete project structure is as follows:\nMS-AutoQC/\n│\n├── src/\n│   └── ms_autoqc/\n│       ├── __main__.py\n│       ├── AcquisitionListener.py\n│       ├── DatabaseFunctions.py\n│       ├── AutoQCProcessing.py\n│       ├── PlotGeneration.py\n│       └── SlackNotifications.py\n│\n├── data/\n│   └── methods/\n│       ├── Settings.db\n│       ├── Example_Library_Pos.msp\n│       └── Example_Library_Neg.msp\n│   └── Example_Instrument.db\n|\n├── auth/\n│   ├── credentials.txt\n│   └── settings.yaml\n|\n├── assets/\n│   ├── favicon.ico\n│   └── styles.css\n|\n├── .gitignore\n├── README.md\n├── requirements.txt\n└── pyproject.toml\n\n\n\nDatabase schema\nData stays in persistence in two types of SQLite databases:\n\nThe instrument database(s)\nThe settings database\n\nAn MS-AutoQC workspace is comprised of the instrument databases and methods directory (which stores MSP/TXT libraries, MS-DIAL parameter files, and the settings database).\nA diagram of the each database’s schema is shown below.\n\nInstrument database\n\n\n\nSettings database\n\n\n\n\nProcessing workflow\nThe diagram below gives a broad overview of how MS-AutoQC listens to instrument runs and processes your data safely and securely. To summarize:\n\nThe user prepares their run sequence and starts an instrument run\nThe user gives MS-AutoQC the sequence file and the data acquisition path\n\nAt this point, the user’s work is done. They can start monitoring their instrument run from the MS-AutoQC dashboard. Now, the MS-AutoQC workflow is initialized.\n\nMS-AutoQC starts “listening” to the data acquisition path\nWhen the instrument starts collecting sample data, MS-AutoQC starts comparing checksums\nOnce the sample data has been acquired, the processing pipeline is launched\nMSConvert converts a copy of the raw data file from closed vendor format to open mzML format\nMS-DIAL processes the mzML file and quantifies internal standards\nMS-AutoQC performs quality control checks (based on user-defined criteria)\nIf there are any QC fails or warnings, the user is notified (if user opted in for notifications)\nQC results are written to the local database and trigger an update to the MS-AutoQC dashboard\n\n\nThe following sections discuss the MS-AutoQC workflow in detail.\n\n1. MS-AutoQC starts listening to the data acquisition path\nTo initialize the workflow, several functions are executed:\n\nThe instrument run is written to the database\nMSP library files are retrieved from the database\nMS-DIAL parameter files are generated for chromatography methods and biological standards\nFilenames are parsed out from the acquisition sequence file\n\nOnce this is done, the acquisition path, filenames, and run ID are passed to the acquisition listener, which is started in the background as a subprocess.\nnew_autoqc_job_setup() function in DashWebApp.py:\n\n\nDashWebApp.py\n\n@app.callback(...)\ndef new_autoqc_job_setup(button_clicks, run_id, instrument_id, chromatography, bio_standards, sequence, metadata, acquisition_path, qc_config_id, job_type):\n\n    \"\"\"\n    This callback initiates the following:\n    1. Writing a new instrument run to the database\n    2. Generate parameters files for MS-DIAL processing\n    3a. Initializing run monitoring at the given directory for an active run, or\n    3b. Iterating through and processing data files for a completed run\n    \"\"\"\n\n    # Write a new instrument run to the database\n    db.insert_new_run(run_id, instrument_id, chromatography, bio_standards, sequence, metadata, qc_config_id)\n\n    # Get MSPs and generate parameters files for MS-DIAL processing\n    for polarity in [\"Positive\", \"Negative\"]:\n\n        # Generate parameters files for processing samples\n        msp_file_path = db.get_msp_file_path(chromatography, polarity)\n        db.generate_msdial_parameters_file(chromatography, polarity, msp_file_path)\n\n        # Generate parameters files for processing each biological standard\n        if bio_standards is not None:\n            for bio_standard in bio_standards:\n                msp_file_path = db.get_msp_file_path(chromatography, polarity, bio_standard)\n                db.generate_msdial_parameters_file(chromatography, polarity, msp_file_path, bio_standard)\n\n    # Get filenames from sequence and filter out preblanks, wash, shutdown, etc.\n    filenames = db.get_filenames_from_sequence(sequence)[\"File Name\"].astype(str).tolist()\n\n    # If this is for an active run, initialize run monitoring at the given directory\n    if job_type == \"active\":\n        listener = subprocess.Popen([\"py\", \"AcquisitionListener.py\", acquisition_path, str(filenames), run_id])\n        return True, False, False, \"\"\n\n    # If this is for a completed run, begin iterating through the files and process them\n    elif job_type == \"completed\":\n        return False, True, False, json.dumps(filenames)\n\n    # Handle form validation errors\n    else:\n        return False, False, True, \"\"\n\nJump to relevant functions:\n\nnew_autoqc_job_setup()\ndb.get_msp_file_path()\ndb.generate_msdial_parameters_file()\ndb.get_filenames_from_sequence()\n\n\n\n2. MS-AutoQC compares checksums\nOnce the acquisition listener has been called, it waits for a file to be created in the data acquisition path.\nUpon file creation, watch_file() is called. It writes an initial MD5 checksum1 of the file to the database, and then initializes an indefinite loop.\nDataAcquisitionEventHandler class in AcquisitionListener.py:\n\n\nAcquisitionListener.py\n\ndef watch_file(self, path, filename, extension, check_interval=180):\n\n    \"\"\"\n    Returns True if MD5 checksum on file matches the MD5 checksum written to the database 3 minutes ago.\n    Effectively determines whether sample acquisition has been completed.\n    \"\"\"\n\n    # Write initial MD5 checksum to database\n    md5_checksum = get_md5(path + filename + \".\" + extension)\n    db.update_md5_checksum(filename, md5_checksum)\n\n    # Watch file indefinitely\n    while os.path.exists(path):\n\n        # Wait 3 minutes\n        time.sleep(check_interval)\n\n        new_md5 = get_md5(path + filename + \".\" + extension)\n        old_md5 = db.get_md5(filename)\n\n        # If the MD5 checksum after 3 mins is the same as before, file is done acquiring\n        if new_md5 == old_md5:\n            break\n        else:\n            db.update_md5_checksum(filename, new_md5)\n    \n    return True\n\nThe loop waits 3 minutes, then computes the file’s MD5 checksum again. If the checksums match, MS-AutoQC then checks whether the next sample has begun acquiring (unless, of course, it is the last sample in the sequence).\nIf checksums match and the next sample in the sequence has begun acquiring, the loop breaks and qc.process_data_file() is called. If either requirement is not filled, the loop repeats and waits again.\nDataAcquisitionEventHandler class in AcquisitionListener.py:\n\n\nAcquisitionListener.py\n\ndef on_created(self, event):\n\n    \"\"\"\n    Listen for data file creation\n    \"\"\"\n\n    # Remove directory path and file extension from filename\n    ...\n\n    # Check if file created is in the sequence\n    if not event.is_directory and filename in self.filenames:\n\n        # Start watching file until sample acquisition is complete\n        sample_acquired = self.watch_file(path, filename, extension)\n\n        # Execute QC processing\n        if sample_acquired:\n            qc.process_data_file(event.src_path, filename, extension, self.run_id)\n\n        # Terminate listener when the last data file is acquired\n        if filename == self.filenames[-1]:\n            self.observer.stop()\n\nJump to relevant functions:\n\non_created()\nwatch_file()\nget_md5()\ndb.get_md5()\ndb.update_md5_checksum()\nqc.process_data_file()\n\n1An MD5 checksum is a 32-character serialized string that represents the contents of a file. If two files have the same MD5 checksum, it is highly likely that they are identical files. Computing this checksum is unlikely to corrupt raw data files, or files of any kind for that matter.\n\n\n3. The processing pipeline is launched\nThe processing pipeline is a wrapper function called qc.process_data_file(), which gets executed when the instrument has finished writing to the data file. It is be described in detail in the upcoming steps.\nIn preparation, this function retrieves the following information from the database:\n\nInstrument run ID\nChromatography method\nList of samples in run\nList of biological standards in run\nMS-DIAL parameters file path\nList of internal standards for chromatography\nList of targeted features for chromatography and biological standard\nMS-DIAL software folder path\n\nIt’s worth noting that this pipeline was intended to be modular2.\nSimply put, the input for whatever data processing software is used is expected to be an mzML file.\nThe output of that data processing software should be then be a peak table, so that calculations and transformations can be made in the succeeding modules.\nFor the purpose of untargeted metabolomics, data is currently processed by calling the MS-DIAL via the command line.\nJump to relevant functions:\n\ndb.get_instrument_run()\ndb.get_samples_in_run()\ndb.get_parameter_file_path()\ndb.get_targeted_features()\ndb.get_internal_standards()\ndb.get_msdial_directory()\nrun_msconvert()\nrun_msdial_processing()\npeak_list_to_dataframe()\nqc_sample()\ndb.write_qc_results()\n\n2As development continues, implementation of other data processing software tools is as straightforward as making a function call to that tool (and storing user parameters, of course).\n\n\n4. MSConvert converts the raw data to mzML format\nTo ensure that the raw data remains untouched (and therefore uncorrupted) by MS-AutoQC, it is copied3 to a local app directory, MS-AutoQC/data.\nMSConvert is then called via the command line. After a few seconds, the mzML file will be saved to MS-AutoQC/data.\nTo prevent unnecessary storage, the copy of the original raw data file is deleted.\n\n\nAutoQCProcessing.py\n\ndef run_msconvert(path, filename, extension, output_folder):\n\n    \"\"\"\n    Converts data files in closed vendor format to open mzML format\n    \"\"\"\n\n    # Remove files in output folder (if any)\n    try:\n        for file in os.listdir(output_folder):\n            os.remove(file)\n    finally:\n        # Copy original data file to output folder\n        shutil.copy2(path + filename + \".\" + extension, output_folder)\n\n    # Get MSConvert.exe\n    try:\n        msconvert_folder = db.get_msconvert_directory()\n        msconvert_exe = '\"' + msconvert_folder + '/msconvert.exe\" '\n    except:\n        print(\"Failed to locate MSConvert.exe!\")\n        traceback.print_exc()\n        return None\n\n    # Run MSConvert in a subprocess\n    command = msconvert_exe + output_folder + filename + \".\" + extension + \" -o \" + output_folder\n    process = psutil.Popen(command)\n    pid = process.pid\n\n    # Check every second for 30 seconds if mzML file was created; if process hangs, terminate and return None\n    for index in range(31):\n        if not subprocess_is_running(pid):\n            break\n        else:\n            if index != 30:\n                time.sleep(1)\n            else:\n                kill_subprocess(pid)\n                return None\n\n    # Delete copy of original data file\n    data_file_copy = output_folder + filename + \".\" + extension\n    os.remove(data_file_copy)\n\n    # Return mzML file path to indicate success\n    return output_folder + filename + \".mzml\"\n\nJump to relevant functions: - run_msconvert()\n3Copying is performed using the native Python function shutil.copy2(), and is unlikely to corrupt the raw data file, or files of any kind.\n\n\n5. MS-DIAL processes the mzML file\nThe run_msdial_processing() function is straightforward: the filename, file directory, and MS-DIAL parameter file are passed to MS-DIAL via a command-line call.\nMS-DIAL takes about 15-30 seconds to process the file (depending on file size) before outputting an .msdial file, which is just a peak table in tab-delimited form.\n\n\nAutoQCProcessing.py\n\ndef run_msdial_processing(filename, msdial_path, parameter_file, input_folder, output_folder):\n\n    \"\"\"\n    Processes data files using MS-DIAL command line tools\n    \"\"\"\n\n    # Navigate to directory containing MS-DIAL\n    home = os.getcwd()\n    os.chdir(msdial_path)\n\n    # Run MS-DIAL\n    command = \"MsdialConsoleApp.exe lcmsdda -i \" + input_folder \\\n              + \" -o \" + output_folder \\\n              + \" -m \" + parameter_file + \" -p\"\n    os.system(command)\n\n    # Clear data file directory for next sample\n    for file in os.listdir(input_folder):\n        filepath = os.path.join(input_folder, file)\n        try:\n            shutil.rmtree(filepath)\n        except OSError:\n            os.remove(filepath)\n\n    # Return to original working directory\n    os.chdir(home)\n\n    # Return .msdial file path\n    return output_folder + \"/\" + filename.split(\".\")[0] + \".msdial\"\n\n\n\n6. MS-AutoQC performs quality control checks\nThe .msdial file is then routed to the peak_list_to_dataframe() function, which searches for internal standards (or targeted features for a biological standard sample) before returning the peak list as a pandas DataFrame for further processing.\n\n\nAutoQCProcessing.py\n\ndef peak_list_to_dataframe(sample_peak_list, internal_standards=None, targeted_features=None):\n\n    \"\"\"\n    Returns DataFrame with m/z, RT, and intensity info for each internal standard in a given sample\n    \"\"\"\n\n    # Convert .msdial file into a DataFrame\n    df_peak_list = pd.read_csv(sample_peak_list, sep=\"\\t\", engine=\"python\", skip_blank_lines=True)\n    df_peak_list.rename(columns={\"Title\": \"Name\"}, inplace=True)\n\n    # Get only the m/z, RT, and intensity columns\n    df_peak_list = df_peak_list[[\"Name\", \"Precursor m/z\", \"RT (min)\", \"Height\"]]\n\n    # Query only internal standards (or targeted features for biological standard)\n    if internal_standards is not None:\n        df_peak_list = df_peak_list.loc[df_peak_list[\"Name\"].isin(internal_standards)]\n    elif targeted_features is not None:\n        df_peak_list = df_peak_list.loc[df_peak_list[\"Name\"].isin(targeted_features)]\n\n    # DataFrame readiness\n    df_peak_list.reset_index(drop=True, inplace=True)\n\n    # Return DataFrame\n    return df_peak_list\n\nThis DataFrame is passed to the qc_sample() function, which performs user-enabled QC checks based on user-defined criteria in Settings &gt; QC Configurations. For MS-AutoQC v1.0, there are four checks performed:\n\nIntensity dropouts cutoff: the minimum number of missing internal standards in a sample to constitute a QC fail\nRT shift from library value cutoff: the minimum retention time shift from the expected library value to constitute a QC fail\nRT shift from in-run average cutoff: the minimum retention time shift from the average RT during the course of the run to constitute a QC fail\nm/z shift from library value cutoff: the minimum m/z shift from the expected library value to constitute a QC fail\n\nThe qc_sample() function returns two objects: the QC result (pass, warning, or fail), and a DataFrame containing QC results, or the results of the four checks detailed above.\nNote: This function is long, comprehensive, and subject to change. If you’re interested in the implementation, check out the documentation.\nFinally, the peak list DataFrame and QC result DataFrame are converted to JSON string format, and written to the relevant table (sample_qc_results or bio_qc_results) in the relevant instrument database using db.write_qc_results():\n\n\nDatabaseFunctions.py\n\ndef write_qc_results(sample_id, run_id, json_mz, json_rt, json_intensity, qc_dataframe, qc_result, is_bio_standard):\n\n    \"\"\"\n    Updates m/z, RT, and intensity info (as dictionary records) in appropriate table upon MS-DIAL processing completion\n    \"\"\"\n\n    # Connect to database\n    db_metadata, connection = connect_to_database(instrument_id)\n\n    # Get \"sample_qc_results\" or \"bio_qc_results\" table\n    if not is_bio_standard:\n        qc_results_table = sa.Table(\"sample_qc_results\", db_metadata, autoload=True)\n    else:\n        qc_results_table = sa.Table(\"bio_qc_results\", db_metadata, autoload=True)\n\n    # Prepare update (insert) of QC results to correct sample row\n    update_qc_results = (\n        sa.update(qc_results_table)\n            .where((qc_results_table.c.sample_id == sample_id)\n                   & (qc_results_table.c.run_id == run_id))\n            .values(precursor_mz=json_mz,\n                    retention_time=json_rt,\n                    intensity=json_intensity,\n                    qc_dataframe=qc_dataframe,\n                    qc_result=qc_result)\n    )\n\n    # Execute UPDATE into database, then close the connection\n    connection.execute(update_qc_results)\n    connection.close()\n\nJump to relevant functions:\n\npeak_list_to_dataframe()\nqc_sample()\ndb.write_qc_results()\n\n\n\n7. The user is notified of QC fails and warnings\nIf quality control checks result in a “Fail” or “Warning” result, an alert will be sent via Slack and/or email (if the user opts in for notifications).\n\n\nAutoQCProcessing.py\n\n# Send Slack notification (if they are enabled)\ntry:\n    if db.slack_notifications_are_enabled():\n        if qc_result != \"Pass\":\n            alert = \"QC \" + qc_result + \": \" + filename\n            slack_bot.send_message(alert)\nexcept:\n    print(\"Failed to send Slack notification.\")\n    traceback.print_exc()\n\nCurrently, this is the simplest component of the pipeline, but posesses a large potential to transform analytical workflows. Future updates will bring more intelligent and informative messages, detailing what went wrong and which component of the LC-MS system may be causing the issue.\nJump to relevant functions:\n\ndb.slack_notifications_are_enabled()\nslack_bot.send_message()\n\n\n\n8. The dashboard is refreshed with QC results\nAfter QC results are written to the database, metadata for the instrument run is updated to trigger a dashboard refresh. The number of samples processed, including the number of passes and fails, is updated using update_sample_counters_for_run().\n\n\nDatabaseFunctions.py\n\ndef update_sample_counters_for_run(instrument_id, run_id, qc_result, latest_sample):\n\n    \"\"\"\n    Increments \"completed\" count, as well as \"pass\" and \"fail\" counts accordingly\n    \"\"\"\n\n    df_instrument_run = get_instrument_run(instrument_id, run_id)\n    completed = df_instrument_run[\"completed\"].astype(int).tolist()[0] + 1\n    passes = df_instrument_run[\"passes\"].astype(int).tolist()[0]\n    fails = df_instrument_run[\"fails\"].astype(int).tolist()[0]\n\n    if qc_result == \"Pass\" or qc_result == \"Warning\":\n        passes = passes + 1\n    elif qc_result == \"Fail\":\n        fails = fails + 1\n\n    db_metadata, connection = connect_to_database(main_database)\n    instrument_runs_table = sa.Table(\"runs\", db_metadata, autoload=True)\n\n    update_status = (\n        sa.update(instrument_runs_table)\n            .where(instrument_runs_table.c.run_id == run_id)\n            .values(\n                completed=completed,\n                passes=passes,\n                fails=fails,\n                latest_sample=latest_sample\n        )\n    )\n\n    connection.execute(update_status)\n    connection.close()\n\nMeanwhile, the web app (served by Dash) stores its copy of the instrument run metadata in the user’s cache. Using a Dash Interval component, a Dash callback is triggered every 15 seconds to compare the run metadata in cache to the run metadata in the database.\n\n\nDashWebApp.py\n\n@app.callback(..., prevent_initial_call=True, suppress_callback_exceptions=True)\ndef load_data(refresh, active_cell, table_data, resources, instrument_id):\n\n    \"\"\"\n    Updates and stores QC results in dcc.Store objects (user's browser session)\n    \"\"\"\n\n    trigger = ctx.triggered_id\n\n    if active_cell:\n        run_id = table_data[active_cell[\"row\"]][\"Run ID\"]\n        status = table_data[active_cell[\"row\"]][\"Status\"]\n\n        # Ensure that refresh does not trigger data parsing if no new samples processed\n        if trigger == \"refresh-interval\":\n            completed_count_in_cache = json.loads(resources)[\"samples_completed\"]\n            actual_completed_count, total = db.get_completed_samples_count(instrument_id, run_id, status)\n\n            if completed_count_in_cache == actual_completed_count:\n                raise PreventUpdate\n\n        # Otherwise, begin route: raw data -&gt; parsed data -&gt; user session cache -&gt; plots\n        return get_qc_results(instrument_id, run_id, status) + (True,)\n\n    else:\n        raise PreventUpdate\n\nWhen a change in the database is detected (via comparing sample counters), all plots in the dashboard are re-populated. The callback continues to check for updates until the end of the instrument run, effectively updating itself in realtime.\nJump to relevant functions:\n\nupdate_sample_counters_for_run()\nget_completed_samples_count()\nload_data()"
  },
  {
    "objectID": "faq.html",
    "href": "faq.html",
    "title": "FAQ",
    "section": "",
    "text": "This section provides a list of frequently asked questions concerning usage, installation, and development of MS-AutoQC.\nIf you don’t find an answer to your question, please feel free to contact us or submit an issue on GitHub."
  },
  {
    "objectID": "faq.html#what-instrument-vendors-are-supported",
    "href": "faq.html#what-instrument-vendors-are-supported",
    "title": "FAQ",
    "section": "What instrument vendors are supported?",
    "text": "What instrument vendors are supported?\nMS-AutoQC was designed to be vendor-agnostic. It parses acquisition sequences based on instrument vendors, and converts data files from closed vendor format to open mzML format before processing.\nHowever, with this initial release (v1.0.0), only Thermo Fisher instruments are fully supported.\nIf you would like to help us develop support for Agilent, Bruker, Sciex, or Waters acquisition sequences and data files, please contact us by sending an email to brian.defelice@czbiohub.org."
  },
  {
    "objectID": "faq.html#is-macos-supported",
    "href": "faq.html#is-macos-supported",
    "title": "FAQ",
    "section": "Is MacOS supported?",
    "text": "Is MacOS supported?\nYes! MS-AutoQC is a Python package, so it can be installed and used on any operating system that runs Python.\nOnce you install MS-AutoQC on your Mac, you have the ability to sign in to your workspace and monitor your QC jobs.\nHowever, you cannot set up QC jobs on MacOS. This is because the processing workflow depends on MSConvert and MS-DIAL, both of which are only supported for Windows."
  },
  {
    "objectID": "faq.html#how-is-quality-control-performed",
    "href": "faq.html#how-is-quality-control-performed",
    "title": "FAQ",
    "section": "How is quality control performed?",
    "text": "How is quality control performed?\nIn short, MS-AutoQC monitors active instrument runs and quantifies internal standards in each sample following acquisition.\nThe RT and m/z of all internal standards found in a sample are compared to their corresponding library values. MS-AutoQC also compares each internal standard’s RT to the in-run average RT, and counts the number of missing internal standards in a sample.\nIf total missing internal standards, absolute RT, in-run RT, or accurate mass fall outside user-defined cutoffs, the sample is deemed a “QC fail”. If the criteria are close to a fail, a “QC warning” is issued instead.\nYou can read more about the processing workflow here."
  },
  {
    "objectID": "faq.html#is-this-software-only-for-metabolomics",
    "href": "faq.html#is-this-software-only-for-metabolomics",
    "title": "FAQ",
    "section": "Is this software only for metabolomics?",
    "text": "Is this software only for metabolomics?\nMS-AutoQC was designed to improve the efficiency of quality control in metabolomics experiments. Support for proteomics data is planned for the future."
  },
  {
    "objectID": "faq.html#what-is-the-recommended-way-to-install-ms-autoqc",
    "href": "faq.html#what-is-the-recommended-way-to-install-ms-autoqc",
    "title": "FAQ",
    "section": "What is the recommended way to install MS-AutoQC?",
    "text": "What is the recommended way to install MS-AutoQC?\nUsing pip, Python’s built-in package installer. Check out the installation guide to see how."
  },
  {
    "objectID": "faq.html#why-does-it-say-python-is-not-recognized-when-i-try-to-install",
    "href": "faq.html#why-does-it-say-python-is-not-recognized-when-i-try-to-install",
    "title": "FAQ",
    "section": "Why does it say “Python is not recognized” when I try to install?",
    "text": "Why does it say “Python is not recognized” when I try to install?\nIf you’re getting this error and you’re sure Python is installed, then you may need to add Python to your system PATH to use it. Follow the steps below:\n\nFrom the taskbar, search for Environment Variables and select the result. You should see the below window:\n\n\n\n\n\nClick the “Environment Variables” button\nUnder “System Variables”, click the Edit button\nClick the New button and paste the following:\n\nC:\\Users\\&lt;username&gt;\\AppData\\Local\\Programs\\Python\\Python310\nBe sure to replace the username and Python version appropriately. For example, if you have Python 3.9, then the version should be Python39.\n\n\n\nOnce you’re done, click OK to save and exit.\nOpen a new Command Prompt window and you should be able to use pip now!"
  },
  {
    "objectID": "faq.html#how-can-i-install-ms-autoqc-manually",
    "href": "faq.html#how-can-i-install-ms-autoqc-manually",
    "title": "FAQ",
    "section": "How can I install MS-AutoQC manually?",
    "text": "How can I install MS-AutoQC manually?\nWhile it is recommended that you use pip, here is a short guide on how to install MS-AutoQC manually.\n\nDownload MS-AutoQC v1.0.0 from GitHub.\nExtract the ZIP file to a folder of your choice.\nOpen a terminal window and enter:\n\ncd &lt;path-to-folder&gt;\npy -m pip install .\nOnce that’s done, you should be able to launch MS-AutoQC by simply entering ms_autoqc in your terminal."
  },
  {
    "objectID": "faq.html#how-can-i-install-ms-autoqc-in-a-virtual-environment",
    "href": "faq.html#how-can-i-install-ms-autoqc-in-a-virtual-environment",
    "title": "FAQ",
    "section": "How can I install MS-AutoQC in a virtual environment?",
    "text": "How can I install MS-AutoQC in a virtual environment?\nIf you would like to protect the integrity of other Python packages or versions installed on your instrument computer, you can opt to install MS-AutoQC in a virtual environment.\nChoose a folder that you would like to store the virtual environment in – denoted by &lt;path-to-venv-folder below – and then enter the following commands in a terminal window:\npy -m venv &lt;path-to-venv-folder&gt;\n&lt;path-to-venv-folder&gt;\\Scripts\\activate\npy -m pip install ms-autoqc\nThat’s it! MS-AutoQC and its dependencies will be installed in your virtual environment.\nNote: Every time you launch MS-AutoQC, you will need to activate your virtual environment first. To do this, just type:\n&lt;path-to-venv-folder&gt;\\Scripts\\activate"
  },
  {
    "objectID": "faq.html#how-can-i-uninstall-ms-autoqc",
    "href": "faq.html#how-can-i-uninstall-ms-autoqc",
    "title": "FAQ",
    "section": "How can I uninstall MS-AutoQC?",
    "text": "How can I uninstall MS-AutoQC?\nTo uninstall MS-AutoQC, simply open a terminal window and type:\npy -m pip uninstall ms-autoqc\nYou will be prompted to confirm by entering Y, and then the package will be uninstalled."
  },
  {
    "objectID": "faq.html#is-my-workspace-deleted-if-i-uninstall-or-re-install-ms-autoqc",
    "href": "faq.html#is-my-workspace-deleted-if-i-uninstall-or-re-install-ms-autoqc",
    "title": "FAQ",
    "section": "Is my workspace deleted if I uninstall or re-install MS-AutoQC?",
    "text": "Is my workspace deleted if I uninstall or re-install MS-AutoQC?\nUninstalling MS-AutoQC does NOT delete workspace data such as QC results and settings for your instrument. These must be removed manually.\nTo delete all workspace data, you can type:\nrmdir /s C:\\Users\\&lt;YOUR-USERNAME-HERE&gt;\\AppData\\Local\\Programs\\python\\&lt;PYTHON-VERSION&gt;\\lib\\site-packages\\ms_autoqc\nNote: The &lt;PYTHON-VERSION&gt; will be denoted as python39 if you have Python 3.9, or python310 if you have Python 3.10, for example.\nIf you installed MS-AutoQC in a virtual environment, then the relevant command is:\nrmdir /s &lt;path-to-venv-folder&gt;\\lib\\site-packages\\ms_autoqc\nOr, if you feel safer to navigate to the folder and delete it yourself, simply paste the above directory into your File Explorer and delete the folders."
  },
  {
    "objectID": "faq.html#why-isnt-msconvert-being-detected-by-ms-autoqc",
    "href": "faq.html#why-isnt-msconvert-being-detected-by-ms-autoqc",
    "title": "FAQ",
    "section": "Why isn’t MSConvert being detected by MS-AutoQC?",
    "text": "Why isn’t MSConvert being detected by MS-AutoQC?\nIf MSConvert is not being detected, try each of the following and see if it solves the problem:\n\nRefresh the page in the browser\nRestart the computer\nReinstall MSConvert\nReinstall .NET Framework"
  },
  {
    "objectID": "faq.html#why-isnt-ms-dial-being-detected-by-ms-autoqc",
    "href": "faq.html#why-isnt-ms-dial-being-detected-by-ms-autoqc",
    "title": "FAQ",
    "section": "Why isn’t MS-DIAL being detected by MS-AutoQC?",
    "text": "Why isn’t MS-DIAL being detected by MS-AutoQC?\nIf MS-DIAL isn’t being located, you might have provided MS-AutoQC the wrong folder (or you might not have provided the location at all).\n\nCheck to make sure that the directory you have provided in Settings &gt; MS-DIAL Configurations isn’t a folder containing the MS-DIAL folder.\nOnce you have saved a new MS-DIAL directory, refresh the page in your browser and try again.\n\nIf this doesn’t solve the problem, check to make sure MsdialConsoleApp.exe exists in your MS-DIAL folder.\n\nIf it doesn’t, you may have a newer version of MS-DIAL. Go to the MS-DIAL website and download any one of the v4 releases.\n\nIf all else fails, try to rename your folder to something with no spaces such as MS-DIAL."
  },
  {
    "objectID": "faq.html#is-an-instrument-run-the-same-as-a-qc-job",
    "href": "faq.html#is-an-instrument-run-the-same-as-a-qc-job",
    "title": "FAQ",
    "section": "Is an “instrument run” the same as a “QC job”?",
    "text": "Is an “instrument run” the same as a “QC job”?\nYes. In the context of this app, both terms can be used interchangeably."
  },
  {
    "objectID": "faq.html#something-went-wrong.-how-do-i-reset-the-app",
    "href": "faq.html#something-went-wrong.-how-do-i-reset-the-app",
    "title": "FAQ",
    "section": "Something went wrong. How do I “reset” the app?",
    "text": "Something went wrong. How do I “reset” the app?\nAs a general rule of thumb, if the UI freezes or produces a bug, try refreshing the page in your browser.\nIf that doesn’t work, try restarting the app by 1) closing the Command Prompt window and 2) launching a new instance using ms_autoqc."
  },
  {
    "objectID": "faq.html#what-happens-if-i-refresh-close-the-app-during-an-active-instrument-run",
    "href": "faq.html#what-happens-if-i-refresh-close-the-app-during-an-active-instrument-run",
    "title": "FAQ",
    "section": "What happens if I refresh / close the app during an active instrument run?",
    "text": "What happens if I refresh / close the app during an active instrument run?\nNothing! The acquisition listener process runs in the background, so it will not be interrupted."
  },
  {
    "objectID": "faq.html#what-happens-if-i-restart-ms_autoqc-from-the-command-prompt-during-an-active-instrument-run",
    "href": "faq.html#what-happens-if-i-restart-ms_autoqc-from-the-command-prompt-during-an-active-instrument-run",
    "title": "FAQ",
    "section": "What happens if I restart ms_autoqc from the Command Prompt during an active instrument run?",
    "text": "What happens if I restart ms_autoqc from the Command Prompt during an active instrument run?\nIf the MS-AutoQC process was interrupted during an instrument run, perform the following steps:\n\n1. Restart MS-AutoQC\nDo this by entering ms_autoqc in a Command Prompt window.\n\n\n2. Select the instrument run from the table\nEvery time you select a run, MS-AutoQC will check to see if the run is active. If the run is active, then it will check to see if the listener process is still running, and restart it as needed."
  },
  {
    "objectID": "faq.html#how-can-i-delete-a-job-and-start-over",
    "href": "faq.html#how-can-i-delete-a-job-and-start-over",
    "title": "FAQ",
    "section": "How can I delete a job and start over?",
    "text": "How can I delete a job and start over?\nFollow the steps below:\n\nSelect the instrument run from the table\nClick the “Delete Job” button\nConfirm and wait for the alert to disappear\nRefresh the page\n\nWhen you refresh the page, the instrument run should no longer appear on the dashboard."
  },
  {
    "objectID": "installation.html",
    "href": "installation.html",
    "title": "Installation",
    "section": "",
    "text": "Installing Rapid-QC-MS is relatively easy and straightforward. You’ll need to:\nIf you run into trouble or have any questions, please feel free to open a new issue on GitHub. You can also visit the Frequently Asked Questions to see if your issue has been documented already."
  },
  {
    "objectID": "installation.html#option-1-install-with-pip-recommended",
    "href": "installation.html#option-1-install-with-pip-recommended",
    "title": "Installation",
    "section": "Option 1: Install with pip (recommended)",
    "text": "Option 1: Install with pip (recommended)\nTo install MS-AutoQC using pip, simply enter the following command in your terminal:\npy -m pip install ms-autoqc\nMS-AutoQC and all required dependencies will be installed automatically. This may take a minute or two. (If you’re curious, you can find a list of these dependencies here.)"
  },
  {
    "objectID": "installation.html#option-2-install-manually",
    "href": "installation.html#option-2-install-manually",
    "title": "Installation",
    "section": "Option 2: Install manually",
    "text": "Option 2: Install manually\nIf you prefer not to use Python’s package manager – or if your LC-MS instrument computer does not have an internet connection – you can manually download and install MS-AutoQC by following the steps below.\n\nDownload MS-AutoQC v1.0.0 from GitHub.\nExtract the ZIP file to a folder of your choice.\nOpen a terminal window and enter:\n\ncd &lt;path-to-folder&gt;\npy -m pip install .\nThat’s it! MS-AutoQC and its dependencies will be installed automatically."
  },
  {
    "objectID": "installation.html#option-3-install-in-a-virtual-environment",
    "href": "installation.html#option-3-install-in-a-virtual-environment",
    "title": "Installation",
    "section": "Option 3: Install in a virtual environment",
    "text": "Option 3: Install in a virtual environment\nIf you would like to protect the integrity of other Python packages or versions installed on your instrument computer, you can opt to install MS-AutoQC in a virtual environment.\nChoose a folder that you would like to store the virtual environment in – denoted by &lt;path-to-venv-folder below – and then enter the following commands in a terminal window:\npy -m venv &lt;path-to-venv-folder&gt;\n&lt;path-to-venv-folder&gt;\\Scripts\\activate\npy -m pip install ms-autoqc\nThat’s it! MS-AutoQC and its dependencies will be installed in your virtual environment.\nNote: Every time you launch MS-AutoQC, you will need to activate your virtual environment first. To do this, just type:\n&lt;path-to-venv-folder&gt;\\Scripts\\activate"
  },
  {
    "objectID": "installation.html#start-ms-autoqc",
    "href": "installation.html#start-ms-autoqc",
    "title": "Installation",
    "section": "Start MS-AutoQC",
    "text": "Start MS-AutoQC\nTo launch MS-AutoQC, simply open a terminal window and type:\nms_autoqc\nIf it doesn’t open automatically, point your webbrowser to localhost:8050 or 127.0.0.1:8050. If you see the screen below, then MS-AutoQC was installed properly!\n\nIf you run into any problems with installing or opening the app, please visit the FAQ on installing MS-AutoQC."
  },
  {
    "objectID": "installation.html#important-note-1",
    "href": "installation.html#important-note-1",
    "title": "Installation",
    "section": "Important note",
    "text": "Important note\nAt this point, if you are installing Rapid-QC-MS only to sign in to your workspace and view the QC dashboard, you can move on to the Quickstart guide to learn how to get started using Rapid-QC-MS.\nIf you are installing Rapid-QC-MS on an instrument computer for the first time, continue with installation of MS-DIAL and MSConvert below."
  },
  {
    "objectID": "quickstart.html",
    "href": "quickstart.html",
    "title": "Quickstart",
    "section": "",
    "text": "If you are setting up Rapid-QC-MS for the first time – or setting up Rapid-QC-MS on a new instrument PC – please follow the steps in this section to properly configure your chromatography methods and QC parameters.\nImportant note: This section does NOT show you how to install Rapid-QC-MS! If you haven’t already, please follow the steps in the installation guide before you start configuring methods and parameters."
  },
  {
    "objectID": "quickstart.html#overview",
    "href": "quickstart.html#overview",
    "title": "Quickstart",
    "section": "Overview",
    "text": "Overview\nThis section will walk you through configuring the bare necessities to set up Rapid-QC-MS jobs for your instrument runs.\n\nStart Rapid-QC-MS\nCreate a new workspace\nConfigure internal standard libraries\nConfigure QC parameters\nSpecify MS-DIAL location\nSet up a new QC job\n\nWhen you’re ready, you can visit the user guide to configure additional settings such as Google Drive sync, Slack/email notifications, biological standards, and MS-DIAL processing parameters."
  },
  {
    "objectID": "quickstart.html#start-ms-autoqc",
    "href": "quickstart.html#start-ms-autoqc",
    "title": "Quickstart",
    "section": "1. Start MS-AutoQC",
    "text": "1. Start MS-AutoQC\nTo launch MS-AutoQC, open a Terminal or Command Prompt window and type:\nms_autoqc"
  },
  {
    "objectID": "quickstart.html#create-a-new-workspace",
    "href": "quickstart.html#create-a-new-workspace",
    "title": "Quickstart",
    "section": "2. Create a new workspace",
    "text": "2. Create a new workspace\nIf you followed the steps in the installation guide correctly, you will be greeted by the following welcome screen:\n\nPlease select I’m setting up Rapid-QC-MS on a new instrument. Then, you will be prompted to give your instrument a unique name and select your instrument’s vendor.\n\n\nOptional: Sync with Google Drive\nIf you opt to set up Google Drive sync, you’ll be able to share your workspace with your team and access QC results from any device.\nThis step is optional and NOT required. If you decide you want to set up sync later, you can do so via Settings &gt; General. If you’d like to set it up now, do the following:\n\nGenerate your client credentials using the Google API Console\nProvide Rapid-QC-MS with your client ID and client secret\nClick “Sign in to Google Drive” and authenticate with your Google account\nClose the tab that says “The authentication flow has completed” and you’re all set.\n\n\n\nOnce you’re done, click Complete setup to create your workspace. After your workspace loads, it should look something like this:"
  },
  {
    "objectID": "quickstart.html#configure-internal-standard-libraries",
    "href": "quickstart.html#configure-internal-standard-libraries",
    "title": "Quickstart",
    "section": "3. Configure internal standard libraries",
    "text": "3. Configure internal standard libraries\nNow that the workspace has been created, you’re ready to start configuring your chromatography methods and corresponding internal standards. The workflow for adding internal standards is simple:\n\nAdd a chromatography method\nSelect the chromatography and polarity to modify\nAdd an internal standard library\nOptional: Set a different MS-DIAL processing configuration\n\n\n3a. Add a chromatography method\nNavigate to Settings (in the top right corner) &gt; Chromatography Methods. Once you’re there, it should look something like this:\n\nIn the Manage chromatography methods section at the top, add a new chromatography method by giving it a name and clicking Add method.\n\nIf successful, you should see your new method in the Chromatography Methods table.\n\n\n3b. Select the chromatography and polarity to modify\nInternal standards must be configured for both positive and negative mode for each chromatography method.\nLet’s start by selecting the chromatography method you created, and then selecting Positive Mode for the polarity.\n\n\n\n\n\n3c. Add an internal standard library\nNow, we can specify our internal standard library. Rapid-QC-MS accepts identification libraries in either MSP or CSV format.\nIt is important to note that MS-DIAL can only perform MS2 spectral matching using MSP libraries. If you use a CSV library, identification will be performed via m/z and RT matches.\nHere is an example internal standard library in CSV format:\n\n\n\nCommon Name\nMS1 m/z\nRT (min)\n\n\n\n\n1_Methionine_d8\n158.1085398\n7.479\n\n\n1_1_Methylnicotinamide_d3\n141.0975946\n6.217\n\n\n1_Creatinine_d3\n117.0850186\n4.908\n\n\n…\n…\n…\n\n\n1_Lysine d8\n155.1630181\n9.578\n\n\n1_Phenylalanine d8\n174.136469\n6.92\n\n\n1_Hippuric acid d5\n185.0969033\n3.011\n\n\n\nAnd here is one internal standard from a library in MSP format:\nNAME: 1_HippuricAcid_d5\nSCANNUMBER: 1229\nRETENTIONTIME: 3.011485\nPRECURSORMZ: 185.0967\nPRECURSORTYPE: [M+H]+\nIONMODE: Positive\nINTENSITY: 2.157809E+07\nISOTOPE: M + 0\nINCHIKEY:\nSMILES:\nFORMULA:\nNum Peaks: 33\n51.02318    5550\n56.94302    2599\n57.93503    32786\n...\n171.3111    3202\n181.08981   2837\n185.09656   4996\nClick the Browse Files button to browse for your MSP or CSV file, then click the Add MSP to  Positive Mode button.\n\nAfter a few seconds, your screen should look something like this:\n\nYou can confirm that the library was successfully added by scrolling up to the Chromatography Methods table and seeing the updated number of Pos (+) Standards.\nThat’s it! Now, you can select Negative Mode from the polarity dropdown and add your negative mode internal standards."
  },
  {
    "objectID": "quickstart.html#configure-qc-parameters",
    "href": "quickstart.html#configure-qc-parameters",
    "title": "Quickstart",
    "section": "4. Configure QC parameters",
    "text": "4. Configure QC parameters\nOnce you have configured your chromatography methods, you can then navigate to Settings &gt; QC Configurations to define your QC criteria. Briefly, these are:\n\nIntensity dropouts cutoff: the minimum number of missing internal standards in a sample to constitute a QC fail\nRT shift from library value cutoff: the minimum retention time shift from the expected library value to constitute a QC fail\nRT shift from in-run average cutoff: the minimum retention time shift from the average RT during the course of the run to constitute a QC fail\nm/z shift from library value cutoff: the minimum m/z shift from the expected library value to constitute a QC fail\n\n\nRapid-QC-MS stores individual parameters in configurations, so that you can configure a specific configuration to fit each chromatography method.\nYou can specify these parameters however you’d like, and enable / disable them as needed. To revert a configuration back to the default recommended settings, simply click the Reset default settings button.\nOnce you’re done, don’t forget to click Save changes!"
  },
  {
    "objectID": "quickstart.html#specify-ms-dial-location",
    "href": "quickstart.html#specify-ms-dial-location",
    "title": "Quickstart",
    "section": "5. Specify MS-DIAL location",
    "text": "5. Specify MS-DIAL location\nThe last thing to do is to specify the location of your MS-DIAL download.\nTo do this, navigate to Settings &gt; MS-DIAL Configurations. Then browse (or enter) the folder path containing your MS-DIAL files into the MS-DIAL download location text field.\nWhen you’re done, click Save Changes.\n\nBe careful not to enter a folder containing the MS-DIAL folder! The MS-DIAL folder you provide should contain an application called MsdialConsoleApp.exe (among many other files)."
  },
  {
    "objectID": "quickstart.html#setup-a-new-qc-job",
    "href": "quickstart.html#setup-a-new-qc-job",
    "title": "Quickstart",
    "section": "6. Setup a new QC job",
    "text": "6. Setup a new QC job\nSetting up a new QC job was designed to be as fast and easy as possible. To get Rapid-QC-MS monitoring an active instrument run (or processing a completed batch), the user simply needs to enter a few fields of information:\n\nInstrument run ID (the name of the job)\nChromatography method\nPreferred QC configuration\nAcquisition sequence file\nData acquisition path (easiest to copy/paste this)\n\n\nRapid-QC-MS will intelligently validate that everything is in place for it to start working. It does this by:\n\nEnsuring that the run ID is unique so that data is not corrupted\nVerifying that your chromatography method has valid internal standard libraries\nEnsuring that your acquisition sequence contains the required columns\nVerifying that the data acquisition path exists\nValidating biological standard libraries and sample metadata columns\n\nOnce it has validated these fields, the blue button will become enabled and you’re all set to press start.\n\nThat’s it! Rapid-QC-MS will take it from here."
  },
  {
    "objectID": "quickstart.html#next-steps",
    "href": "quickstart.html#next-steps",
    "title": "Quickstart",
    "section": "Next steps",
    "text": "Next steps\nOnce you feel comfortable configuring the bare necessities for Rapid-QC-MS, you can read the following sections in the user guide to customize your workspace for maximum efficiency:\n\nIncorporate sample metadata\nSet up biological standards\nConfigure MS-DIAL processing parameters\nEnable Google Drive sync\nAdd instruments to workspace (sync required)\nGrant / revoke workspace access (sync required)\nSign in to workspace from external devices (sync required)\nRegister for email notifications (sync required)\nRegister for Slack notifications"
  },
  {
    "objectID": "installation.html#option-1-install-in-a-virtual-environment-recommended",
    "href": "installation.html#option-1-install-in-a-virtual-environment-recommended",
    "title": "Installation",
    "section": "Option 1: Install in a virtual environment (recommended)",
    "text": "Option 1: Install in a virtual environment (recommended)\nChoose a location where you would like to store the virtual environment; some choices might be C:\\Users\\username\\venvs\\rapidqcms or C:\\Users\\username\\documents\\rapidqcms\\env. Whatever path is choosen will be denoted by &lt;path-to-venv-folder&gt; below.\nOpen a terminal (Windows Terminal, command prompt, powershell) and enter the following commands, denoted by ‘&gt;’\n\n\n\n\n\n\nNote\n\n\n\nThese commands are for a Windows environment. Unix/mac users would replace ‘py’ with ‘python3’.\n\n\n&gt; py -3.# -m venv &lt;path-to-venv-folder&gt;\nwhere -3.# is the version of python you want to use, eg py -3.11. You can get a list of python versions installed on your system by running &gt; py -0.\n\nNext, activate the virtual environment by entering\n&gt; .\\&lt;path-to-venv-folder&gt;\\Scripts\\activate\n\n\n\n\n\n\nNote\n\n\n\nPowershell users may encounter issues activating the virtual environment, depending on their system security settings. Running set-executionpolicy RemoteSigned and\\or using Scripts\\activate.ps1 should solve this problem.\n\n\nYou can deactivate the virtual environment by entering ‘deactivate’ at the prompt, or just closing the terminal.\nNext, update the pip, setuptools, and wheel packages, and then install rapid-qc-ms.\n(yourenv) &gt; py -m pip install --upgrade pip, setuptools, wheel\n(yourenv) &gt; py -m pip install rapid-qc-ms\nRapid-QC-MS and all required python dependencies will be installed automatically. This may take a minute or two.\n\n\n\n\n\n\nImportant\n\n\n\nYou will need to activate your virtual environment each time before launching rapid-qc-ms.\n\n\nAlternatively, you can create a short batch (.bat) file on windows to automate this process for you. Create a new text file and rename it to ‘start RapidQC.bat’ or similar, it may warn you about changing the extension - press yes.\nOpen the new .bat file in any text editor of your choice, notepad works fine, and paste the following (hover over the numbers at the right for explanations of each line)\n1call &lt;path-to-venv-folder&gt;\\Scripts\\activate\n2rapidqcms\n3cmd /k\n\n1\n\nCall is a batch command that calls another batch or script, in this case the activate script for the python virtual environment. This starts the virtual environment.\n\n2\n\nRapidqcms is then executed within the virtual environment, and starts the package.\n\n3\n\nKeeps the command prompt window open until closed by the user (useful for capturing errors) Double click on the file to run.\n\n\n\n\n\n\n\n\nExample Commands\n\n\n\n\n\nI’m using windows terminal, your exact prompt may look a little different\nPS C:\\Users\\user\\myvirtualenvs\\rapidqcms&gt; py -3.11 -m venv env\nwill create a new folder named ‘env’ in the rapidqcms folder. We could also run\nPS C:\\&gt; py -3.11 -m venv C:\\Users\\user\\myvirtualenvs\\rapidqcms\\env\nthen\nPS C:\\Users\\user\\myvirtualenvs\\rapidqcms&gt; .\\env\\Scripts\\activate\nActivates the virtual environment, notice the (env) to the left of the prompt\n(env) PS C:\\Users\\user\\myvirtualenvs\\rapidqcms&gt; py -m pip install --upgrade pip, setuptools, wheel\nthis will produce some terminal output and may download updates\n(env) PS C:\\Users\\user\\myvirtualenvs\\rapidqcms&gt; py -m pip install rapid-qc-ms\nthis will produce a lot of terminal output and download several packages\n(env) PS C:\\Users\\user\\myvirtualenvs\\rapidqcms&gt; rapidqcms\nstarts the package."
  },
  {
    "objectID": "installation.html#option-2-install-with-pip",
    "href": "installation.html#option-2-install-with-pip",
    "title": "Installation",
    "section": "Option 2: Install with pip",
    "text": "Option 2: Install with pip\nIf you have no other python software installed on the computer, and don’t plan on installing any in the future, it can be more expedient to install Rapid-QC-MS directly using pip, simply enter the following command in your terminal:\npy -m pip install Rapid-QC-MS\nRapid-QC-MS and all required dependencies will be installed automatically. This may take a minute or two."
  },
  {
    "objectID": "installation.html#option-3-install-manually",
    "href": "installation.html#option-3-install-manually",
    "title": "Installation",
    "section": "Option 3: Install manually",
    "text": "Option 3: Install manually\nIf your LC-MS instrument computer does not have an internet connection – you can manually download and install Rapid-QC-MS locally.\n\nDownload Rapid-QC-MS v1.0.0 from GitHub.\nExtract the ZIP file to a folder of your choice.\nOptionally, you can setup and activate a virtual environment as outlined in step 1 (recommended)\nOpen a terminal window and enter:\n\ncd &lt;path-to-folder&gt;\npy -m pip install ."
  },
  {
    "objectID": "installation.html#start-rapid-qc-ms",
    "href": "installation.html#start-rapid-qc-ms",
    "title": "Installation",
    "section": "Start Rapid-QC-MS",
    "text": "Start Rapid-QC-MS\nTo start Rapid-QC-MS, activate your virtual environment (if not already activated)\n&gt; .\\&lt;path-to-venv-folder&gt;\\Scripts\\activate\nthen call the package\n(yourenvname) &gt; rapidqcms\n\n\n\n\n\n\nWarning\n\n\n\nIf you encounter a path error, you may need to navigate to the installation folder within the python directory, assuming default installation settings:\nC:\\Users\\username\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rapid-qc-ms\\src&gt; rapidqcms\n\n\nYour browser may open automatically, if not point your browser to localhost:8050 or 127.0.0.1:8050. If you see the screen below, then Rapid-QC-MS was installed properly!\n\nIf you run into any problems with installing or opening the app, check the FAQ and/or post an issue on github."
  },
  {
    "objectID": "installation.html#option-2-install-directly-with-pip",
    "href": "installation.html#option-2-install-directly-with-pip",
    "title": "Installation",
    "section": "Option 2: Install directly with pip",
    "text": "Option 2: Install directly with pip\nIf you have no other python software installed on the computer, and don’t plan on installing any in the future, it can be more expedient to install Rapid-QC-MS directly using pip, simply enter the following command in your terminal:\npy -m pip install Rapid-QC-MS"
  },
  {
    "objectID": "installation.html#important-note",
    "href": "installation.html#important-note",
    "title": "Installation",
    "section": "Important note",
    "text": "Important note\nAt this point, if you are installing Rapid-QC-MS only to sign in to your workspace and view the QC dashboard, you can move on to the Quickstart guide to learn how to get started using Rapid-QC-MS.\nIf you are installing Rapid-QC-MS on an instrument computer for the first time, continue with installation of MS-DIAL and MSConvert below."
  },
  {
    "objectID": "quickstart.html#start-rapid-qc-ms",
    "href": "quickstart.html#start-rapid-qc-ms",
    "title": "Quickstart",
    "section": "1. Start Rapid-QC-MS",
    "text": "1. Start Rapid-QC-MS\nTo launch Rapid-QC-MS, open a Terminal or Command Prompt window and type:\n&gt; .\\&lt;path-to-venv-folder&gt;\\Scripts\\activate\n(yourenv) &gt; rapidqcms"
  },
  {
    "objectID": "quickstart.html#instrument-computer-workspace-setup",
    "href": "quickstart.html#instrument-computer-workspace-setup",
    "title": "Quickstart",
    "section": "2. Instrument computer workspace setup",
    "text": "2. Instrument computer workspace setup\nAfter following the installation guide, you should be greeted by the following welcome screen:\n\nSelect I’m setting up Rapid-QC-MS on a new instrument. Then, you will be prompted to give your instrument a unique name (at least 4 characters) and select your instrument’s vendor.\n\n\nOptional: Sync with Google Drive\nIf you opt to set up Google Drive sync, you’ll be able to share your workspace with your team and access QC results from any device.\nThis step is optional and NOT required. If you decide you want to set up sync later, you can do so via Settings &gt; General. If you’d like to set it up now, do the following:\n\nGenerate your client credentials using the Google API Console\nProvide Rapid-QC-MS with your client ID and client secret\nClick “Sign in to Google Drive” and authenticate with your Google account\nClose the tab that says “The authentication flow has completed” and you’re all set.\n\n\n\nOnce you’re done, click Complete setup to create your workspace. After your workspace loads, it should look something like this:"
  }
]