[
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "Overview",
    "section": "",
    "text": "Many different things can go wrong during an LC-MS instrument run, leading to unusable data. That’s why it is crucial to stop a run and troubleshoot if something is wrong.\nMany metabolomics labs have various quality control measures in place for every sample preparation protocol, such as internal standards or biological “benchmark” standards. However, analyzing the data from these QC markers can be tedious and time-consuming.\nThis section describes the various features of MS-AutoQC, and how they can help inform on the quality of your untargeted metabolomics data in a time-efficient manner."
  },
  {
    "objectID": "overview.html#retention-time-across-samples",
    "href": "overview.html#retention-time-across-samples",
    "title": "Overview",
    "section": "Retention time across samples",
    "text": "Retention time across samples\nPlotting retention time values for a given internal standard gives insight into retention time shifts, which can indicate any of the following:\n\nIncorrect mobile phase concentration\nChanges in flow rate\nChanges in column temperature\nFaulty / damaged column\n\nThe retention time vs. sample plot provides an at-a-glance view at trends or issues with chromatography. The user can hover over each marker (point) to display relevant metadata for a sample, zoom or pan over the graph, and even grab a screenshot for easy sharing with teammates.\nTry it out yourself below!\n\n\n\n                                                \n\n\nAdditionally, the user can select an internal standard using the dropdown, or seek through them using the previous / next buttons. MS-AutoQC provides global filters for polarity and sample type in the sidebar as well."
  },
  {
    "objectID": "overview.html#intensity-across-samples",
    "href": "overview.html#intensity-across-samples",
    "title": "Overview",
    "section": "Intensity across samples",
    "text": "Intensity across samples\nPlotting intensity (peak height) values can give insight into sample preparation and ionization variability. Low internal standard intensities could indicate:\n\nBad injection\nError in sample preparation\nInstrument performance (sample not ionizing correctly)\n\nMS-AutoQC allows you to filter the intensity vs. sample plot by samples, pools, or blanks using the plot filter in the sidebar. You can also scroll through the plot using the plot scroll bar at the bottom."
  },
  {
    "objectID": "overview.html#delta-mz-across-samples",
    "href": "overview.html#delta-mz-across-samples",
    "title": "Overview",
    "section": "Delta m/z across samples",
    "text": "Delta m/z across samples\nThe mass accuracy of a mass spectrometer can be evaluated by plotting delta m/z values, which can also provide insight into the instrument’s overall performance.\nWhile it may not always be immediately apparent if there are problems with the mass accuracy, the delta m/z vs. samples plot ensures the reliability of an experiment’s results."
  },
  {
    "objectID": "overview.html#sample-information-card",
    "href": "overview.html#sample-information-card",
    "title": "Overview",
    "section": "Sample information card",
    "text": "Sample information card\nTo investigate a sample more closely, you can select one from the sample table (or click a marker on the plot!) and the sample information card will open.\nThis card conveniently aggregates sample information from the sequence, metadata, processed data, and QC results into one place."
  },
  {
    "objectID": "overview.html#new-job-setup",
    "href": "overview.html#new-job-setup",
    "title": "Overview",
    "section": "New job setup",
    "text": "New job setup\nSetting up a new MS-AutoQC job is designed to be as fast and easy as possible. To get the AutoQC algorithm running, the user just needs to enter:\n\nRun ID\nChromatography\nBiological standards (optional)\nAcquisition sequence file\nSample metadata file\nData file directory\n\nThe form then validates resources and gives the user intelligent feedback. Once the user has chosen whether the job is for an active or completed instrument run, the new job can be executed."
  },
  {
    "objectID": "overview.html#google-drive-and-slack",
    "href": "overview.html#google-drive-and-slack",
    "title": "Overview",
    "section": "Google Drive and Slack",
    "text": "Google Drive and Slack\nIn Settings > General, the user is able to:\n\nEnable Google Drive cloud sync\nManage workspace access among users\nRegister a Slack bot for Slack notifications\nRegister addresses for email notifications"
  },
  {
    "objectID": "overview.html#chromatography-methods",
    "href": "overview.html#chromatography-methods",
    "title": "Overview",
    "section": "Chromatography methods",
    "text": "Chromatography methods\nIn Settings > Chromatography Methods, the user is able to:\n\nAdd / delete chromatography methods\nAdd internal standard libraries for each chromatography–polarity combination\nSet a custom processing configuration for each chromatography method"
  },
  {
    "objectID": "overview.html#biological-standards",
    "href": "overview.html#biological-standards",
    "title": "Overview",
    "section": "Biological standards",
    "text": "Biological standards\nIn Settings > Biological Standards, the user is able to:\n\nAdd / delete biological standards with sequence identifiers\nAdd metabolite libraries for each biological standard–chromatography–polarity combination\nSet custom processing configuration for each biological standard–chromatography combination"
  },
  {
    "objectID": "overview.html#autoqc-configurations",
    "href": "overview.html#autoqc-configurations",
    "title": "Overview",
    "section": "AutoQC configurations",
    "text": "AutoQC configurations\nIn Settings > AutoQC Configurations, the user is able to:\n\nAdd / delete AutoQC configurations\nSet cutoff for intensity dropouts\nSet cutoff for RT shift from library value\nSet cutoff for RT shift from in-run average\nSet cutoff for m/z drift from library value"
  },
  {
    "objectID": "overview.html#ms-dial-configurations",
    "href": "overview.html#ms-dial-configurations",
    "title": "Overview",
    "section": "MS-DIAL configurations",
    "text": "MS-DIAL configurations\nIn Settings > MS-DIAL Configurations, the user is able to:\n\nAdd / delete MS-DIAL configurations\nSet data collection parameters\nSet centroid parameters\nSet peak detection parameters\nSet identification parameters\nSet alignment parameters"
  },
  {
    "objectID": "documentation.html",
    "href": "documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "This section details the backend data infrastructure and data processing pipeline packaged into MS-AutoQC, as well as some of the structure and logic of the Dash callbacks that serve the frontend app interface.\nIf you have any questions, concerns, or suggestions about the design of MS-AutoQC, please don’t hesitate to contact us!\n\nDesign pattern\nMS-AutoQC was designed with flexibility and scalability in mind. The project follows the MVC (Model-View-Controller) design pattern. The separation of concerns allows multiple developers to manage and make changes to the frontend and backend easily.\n\n\nFrontend\nThe frontend consists of a Dash app, which launches on startup and can be used from the browser. Dash is a powerful, open-source Python framework (built atop React, Plotly, and Flask) for building web applications.\nIn summary, components make up a user interface, and callbacks map inputs from one component to outputs of another. There is very little boilerplate code required to get started, and the library is extremely well-documented by the developers and community.\n\n\nBackend\nThe backend is organized into five different files:\n\nAcquisitionListener defines classes and functions for monitoring data acquisition paths and processing data files.\nDatabaseFunctions provides highly-abstracted API for reading from and writing to databases.\nAutoQCProcessing is a modular pipeline for processing data files, performing QC checks, and writing QC results to the database\nSlackNotifications defines functions for controlling the Slack bot\nPlotGeneration parses QC results from the database to generate Plotly graphs\n\nThe complete project structure is as follows:\nMS-AutoQC/\n│\n├── src/\n│   └── ms_autoqc/\n│       ├── __main__.py\n│       ├── AcquisitionListener.py\n│       ├── DatabaseFunctions.py\n│       ├── AutoQCProcessing.py\n│       ├── PlotGeneration.py\n│       └── SlackNotifications.py\n│\n├── data/\n│   └── methods/\n│       ├── Settings.db\n│       ├── Example_Library_Pos.msp\n│       └── Example_Library_Neg.msp\n│   └── Example_Instrument.db\n|\n├── auth/\n│   ├── credentials.txt\n│   └── settings.yaml\n|\n├── assets/\n│   ├── favicon.ico\n│   └── styles.css\n|\n├── .gitignore\n├── README.md\n├── requirements.txt\n└── pyproject.toml\n\n\n\nDatabase schema\nData stays in persistence in two types of SQLite databases:\n\nThe instrument database(s)\nThe settings database\n\nAn MS-AutoQC workspace is comprised of the instrument databases and methods directory (which stores MSP/TXT libraries, MS-DIAL parameter files, and the settings database).\nA diagram of the each database’s schema is shown below.\n\nInstrument database\n\n\n\nSettings database\n\n\n\n\nProcessing workflow\nThe diagram below gives a broad overview of how MS-AutoQC listens to instrument runs and processes your data safely and securely. To summarize:\n\nThe user prepares their run sequence and starts an instrument run\nThe user gives MS-AutoQC the sequence file and the data acquisition path\n\nAt this point, the user’s work is done. They can start monitoring their instrument run from the MS-AutoQC dashboard. Now, the MS-AutoQC workflow is initialized.\n\nMS-AutoQC starts “listening” to the data acquisition path\nWhen the instrument starts collecting sample data, MS-AutoQC starts comparing checksums\nOnce the sample data has been acquired, the processing pipeline is launched\nMSConvert converts a copy of the raw data file from closed vendor format to open mzML format\nMS-DIAL processes the mzML file and quantifies internal standards\nMS-AutoQC performs quality control checks (based on user-defined criteria)\nIf there are any QC fails or warnings, the user is notified (if user opted in for notifications)\nQC results are written to the local database and trigger an update to the MS-AutoQC dashboard\n\n\nThe following sections discuss the MS-AutoQC workflow in detail.\n\n1. MS-AutoQC starts listening to the data acquisition path\nTo initialize the workflow, several functions are executed:\n\nThe instrument run is written to the database\nMSP library files are retrieved from the database\nMS-DIAL parameter files are generated for chromatography methods and biological standards\nFilenames are parsed out from the acquisition sequence file\n\nOnce this is done, the acquisition path, filenames, and run ID are passed to the acquisition listener, which is started in the background as a subprocess.\nnew_autoqc_job_setup() function in DashWebApp.py:\n\n\nDashWebApp.py\n\n@app.callback(...)\ndef new_autoqc_job_setup(button_clicks, run_id, instrument_id, chromatography, bio_standards, sequence, metadata, acquisition_path, qc_config_id, job_type):\n\n    \"\"\"\n    This callback initiates the following:\n    1. Writing a new instrument run to the database\n    2. Generate parameters files for MS-DIAL processing\n    3a. Initializing run monitoring at the given directory for an active run, or\n    3b. Iterating through and processing data files for a completed run\n    \"\"\"\n\n    # Write a new instrument run to the database\n    db.insert_new_run(run_id, instrument_id, chromatography, bio_standards, sequence, metadata, qc_config_id)\n\n    # Get MSPs and generate parameters files for MS-DIAL processing\n    for polarity in [\"Positive\", \"Negative\"]:\n\n        # Generate parameters files for processing samples\n        msp_file_path = db.get_msp_file_path(chromatography, polarity)\n        db.generate_msdial_parameters_file(chromatography, polarity, msp_file_path)\n\n        # Generate parameters files for processing each biological standard\n        if bio_standards is not None:\n            for bio_standard in bio_standards:\n                msp_file_path = db.get_msp_file_path(chromatography, polarity, bio_standard)\n                db.generate_msdial_parameters_file(chromatography, polarity, msp_file_path, bio_standard)\n\n    # Get filenames from sequence and filter out preblanks, wash, shutdown, etc.\n    filenames = db.get_filenames_from_sequence(sequence)[\"File Name\"].astype(str).tolist()\n\n    # If this is for an active run, initialize run monitoring at the given directory\n    if job_type == \"active\":\n        listener = subprocess.Popen([\"py\", \"AcquisitionListener.py\", acquisition_path, str(filenames), run_id])\n        return True, False, False, \"\"\n\n    # If this is for a completed run, begin iterating through the files and process them\n    elif job_type == \"completed\":\n        return False, True, False, json.dumps(filenames)\n\n    # Handle form validation errors\n    else:\n        return False, False, True, \"\"\n\nJump to relevant functions:\n\nnew_autoqc_job_setup()\ndb.get_msp_file_path()\ndb.generate_msdial_parameters_file()\ndb.get_filenames_from_sequence()\n\n\n\n2. MS-AutoQC compares checksums\nOnce the acquisition listener has been called, it waits for a file to be created in the data acquisition path.\nUpon file creation, watch_file() is called. It writes an initial MD5 checksum1 of the file to the database, and then initializes an indefinite loop.\nDataAcquisitionEventHandler class in AcquisitionListener.py:\n\n\nAcquisitionListener.py\n\ndef watch_file(self, path, filename, extension, check_interval=180):\n\n    \"\"\"\n    Returns True if MD5 checksum on file matches the MD5 checksum written to the database 3 minutes ago.\n    Effectively determines whether sample acquisition has been completed.\n    \"\"\"\n\n    # Write initial MD5 checksum to database\n    md5_checksum = get_md5(path + filename + \".\" + extension)\n    db.update_md5_checksum(filename, md5_checksum)\n\n    # Watch file indefinitely\n    while os.path.exists(path):\n\n        # Wait 3 minutes\n        time.sleep(check_interval)\n\n        new_md5 = get_md5(path + filename + \".\" + extension)\n        old_md5 = db.get_md5(filename)\n\n        # If the MD5 checksum after 3 mins is the same as before, file is done acquiring\n        if new_md5 == old_md5:\n            break\n        else:\n            db.update_md5_checksum(filename, new_md5)\n    \n    return True\n\nThe loop waits 3 minutes, then computes the file’s MD5 checksum again. If the checksums match, the loop breaks and qc.process_data_file() is called. If not, the loop repeats.\nDataAcquisitionEventHandler class in AcquisitionListener.py:\n\n\nAcquisitionListener.py\n\ndef on_created(self, event):\n\n    \"\"\"\n    Listen for data file creation\n    \"\"\"\n\n    # Remove directory path and file extension from filename\n    ...\n\n    # Check if file created is in the sequence\n    if not event.is_directory and filename in self.filenames:\n\n        # Start watching file until sample acquisition is complete\n        sample_acquired = self.watch_file(path, filename, extension)\n\n        # Execute QC processing\n        if sample_acquired:\n            qc.process_data_file(event.src_path, filename, extension, self.run_id)\n\n        # Terminate listener when the last data file is acquired\n        if filename == self.filenames[-1]:\n            self.observer.stop()\n\nJump to relevant functions:\n\non_created()\nwatch_file()\nget_md5()\ndb.get_md5()\ndb.update_md5_checksum()\nqc.process_data_file()\n\n1An MD5 checksum is a 32-character serialized string that represents the contents of a file. If two files have the same MD5 checksum, it is highly likely that they are identical files. Computing this checksum is unlikely to corrupt raw data files, or files of any kind for that matter.\n\n\n3. The processing pipeline is launched\nThe processing pipeline is a wrapper function called qc.process_data_file(), which gets executed when the instrument has finished writing to the data file. It is be described in detail in the upcoming steps.\nIn preparation, this function retrieves the following information from the database:\n\nInstrument run ID\nChromatography method\nList of samples in run\nList of biological standards in run\nMS-DIAL parameters file path\nList of internal standards for chromatography\nList of targeted features for chromatography and biological standard\nMS-DIAL software folder path\n\nIt’s worth noting that this pipeline was intended to be modular2.\nSimply put, the input for whatever data processing software is used is expected to be an mzML file.\nThe output of that data processing software should be then be a peak table, so that calculations and transformations can be made in the succeeding modules.\nFor the purpose of untargeted metabolomics, data is currently processed by calling the MS-DIAL via the command line.\nJump to relevant functions:\n\ndb.get_instrument_run()\ndb.get_samples_in_run()\ndb.get_parameter_file_path()\ndb.get_targeted_features()\ndb.get_internal_standards()\ndb.get_msdial_directory()\nrun_msconvert()\nrun_msdial_processing()\npeak_list_to_dataframe()\nqc_sample()\ndb.write_qc_results()\n\n2As development continues, implementation of other data processing software tools is as straightforward as making a function call to that tool (and storing user parameters, of course).\n\n\n4. MSConvert converts the raw data to mzML format\nTo ensure that the raw data remains untouched (and therefore uncorrupted) by MS-AutoQC, it is copied3 to a local app directory, MS-AutoQC/data.\nMSConvert is then called via the command line. After a few seconds, the mzML file will be saved to MS-AutoQC/data.\nTo prevent unnecessary storage, the copy of the original raw data file is deleted.\n\n\nAutoQCProcessing.py\n\ndef run_msconvert(path, filename, extension, output_folder):\n\n    \"\"\"\n    Converts data files in closed vendor format to open mzML format\n    \"\"\"\n\n    # Remove files in output folder (if any)\n    try:\n        for file in os.listdir(output_folder):\n            os.remove(file)\n    finally:\n        # Copy original data file to output folder\n        shutil.copy2(path + filename + \".\" + extension, output_folder)\n\n    # Get MSConvert.exe\n    try:\n        msconvert_folder = db.get_msconvert_directory()\n        msconvert_exe = '\"' + msconvert_folder + '/msconvert.exe\" '\n    except:\n        print(\"Failed to locate MSConvert.exe!\")\n        traceback.print_exc()\n        return None\n\n    # Run MSConvert in a subprocess\n    command = msconvert_exe + output_folder + filename + \".\" + extension + \" -o \" + output_folder\n    process = psutil.Popen(command)\n    pid = process.pid\n\n    # Check every second for 30 seconds if mzML file was created; if process hangs, terminate and return None\n    for index in range(31):\n        if not subprocess_is_running(pid):\n            break\n        else:\n            if index != 30:\n                time.sleep(1)\n            else:\n                kill_subprocess(pid)\n                return None\n\n    # Delete copy of original data file\n    data_file_copy = output_folder + filename + \".\" + extension\n    os.remove(data_file_copy)\n\n    # Return mzML file path to indicate success\n    return output_folder + filename + \".mzml\"\n\nJump to relevant functions: - run_msconvert()\n3Copying is performed using the native Python function shutil.copy2(), and is unlikely to corrupt the raw data file, or files of any kind.\n\n\n5. MS-DIAL processes the mzML file\nThe run_msdial_processing() function is straightforward: the filename, file directory, and MS-DIAL parameter file are passed to MS-DIAL via a command-line call.\nMS-DIAL takes about 15-30 seconds to process the file (depending on file size) before outputting an .msdial file, which is just a peak table in tab-delimited form.\n\n\nAutoQCProcessing.py\n\ndef run_msdial_processing(filename, msdial_path, parameter_file, input_folder, output_folder):\n\n    \"\"\"\n    Processes data files using MS-DIAL command line tools\n    \"\"\"\n\n    # Navigate to directory containing MS-DIAL\n    home = os.getcwd()\n    os.chdir(msdial_path)\n\n    # Run MS-DIAL\n    command = \"MsdialConsoleApp.exe lcmsdda -i \" + input_folder \\\n              + \" -o \" + output_folder \\\n              + \" -m \" + parameter_file + \" -p\"\n    os.system(command)\n\n    # Clear data file directory for next sample\n    for file in os.listdir(input_folder):\n        filepath = os.path.join(input_folder, file)\n        try:\n            shutil.rmtree(filepath)\n        except OSError:\n            os.remove(filepath)\n\n    # Return to original working directory\n    os.chdir(home)\n\n    # Return .msdial file path\n    return output_folder + \"/\" + filename.split(\".\")[0] + \".msdial\"\n\n\n\n6. MS-AutoQC performs quality control checks\nThe .msdial file is then routed to the peak_list_to_dataframe() function, which searches for internal standards (or targeted features for a biological standard sample) before returning the peak list as a pandas DataFrame for further processing.\n\n\nAutoQCProcessing.py\n\ndef peak_list_to_dataframe(sample_peak_list, internal_standards=None, targeted_features=None):\n\n    \"\"\"\n    Returns DataFrame with m/z, RT, and intensity info for each internal standard in a given sample\n    \"\"\"\n\n    # Convert .msdial file into a DataFrame\n    df_peak_list = pd.read_csv(sample_peak_list, sep=\"\\t\", engine=\"python\", skip_blank_lines=True)\n    df_peak_list.rename(columns={\"Title\": \"Name\"}, inplace=True)\n\n    # Get only the m/z, RT, and intensity columns\n    df_peak_list = df_peak_list[[\"Name\", \"Precursor m/z\", \"RT (min)\", \"Height\"]]\n\n    # Query only internal standards (or targeted features for biological standard)\n    if internal_standards is not None:\n        df_peak_list = df_peak_list.loc[df_peak_list[\"Name\"].isin(internal_standards)]\n    elif targeted_features is not None:\n        df_peak_list = df_peak_list.loc[df_peak_list[\"Name\"].isin(targeted_features)]\n\n    # DataFrame readiness\n    df_peak_list.reset_index(drop=True, inplace=True)\n\n    # Return DataFrame\n    return df_peak_list\n\nThis DataFrame is passed to the qc_sample() function, which performs user-enabled QC checks based on user-defined criteria in Settings > QC Configurations. For MS-AutoQC v1.0, there are four checks performed:\n\nIntensity dropouts cutoff: how many internal standards are missing in the sample?\nRT shift from library value cutoff: how many retention times are shifted from the expected value for the chromatography method?\nRT shift from in-run average cutoff: how many retention times are shifted from their average RT during the run?\nm/z shift from library value cutoff: how many precursor masses are shifted from the expected value for the internal standard?\n\nThe qc_sample() function returns two objects: the QC result (pass, warning, or fail), and a DataFrame containing QC results, or the results of the four checks detailed above.\nNote: This function is long, comprehensive, and subject to change. If you’re interested in the implementation, you can check it out in AutoQCProcessing.py on GitHub.\nFinally, the peak list DataFrame and QC result DataFrame are converted to JSON string format, and written to the relevant table (sample_qc_results or bio_qc_results) in the relevant instrument database using db.write_qc_results():\n\n\nDatabaseFunctions.py\n\ndef write_qc_results(sample_id, run_id, json_mz, json_rt, json_intensity, qc_dataframe, qc_result, is_bio_standard):\n\n    \"\"\"\n    Updates m/z, RT, and intensity info (as dictionary records) in appropriate table upon MS-DIAL processing completion\n    \"\"\"\n\n    # Connect to database\n    db_metadata, connection = connect_to_database(instrument_id)\n\n    # Get \"sample_qc_results\" or \"bio_qc_results\" table\n    if not is_bio_standard:\n        qc_results_table = sa.Table(\"sample_qc_results\", db_metadata, autoload=True)\n    else:\n        qc_results_table = sa.Table(\"bio_qc_results\", db_metadata, autoload=True)\n\n    # Prepare update (insert) of QC results to correct sample row\n    update_qc_results = (\n        sa.update(qc_results_table)\n            .where((qc_results_table.c.sample_id == sample_id)\n                   & (qc_results_table.c.run_id == run_id))\n            .values(precursor_mz=json_mz,\n                    retention_time=json_rt,\n                    intensity=json_intensity,\n                    qc_dataframe=qc_dataframe,\n                    qc_result=qc_result)\n    )\n\n    # Execute UPDATE into database, then close the connection\n    connection.execute(update_qc_results)\n    connection.close()\n\nJump to relevant functions:\n\npeak_list_to_dataframe()\nqc_sample()\ndb.write_qc_results()\n\n\n\n7. The user is notified of QC fails and warnings\nIf quality control checks result in a “Fail” or “Warning” result, an alert will be sent via Slack and/or email (if the user opts in for notifications).\n\n\nAutoQCProcessing.py\n\n# Send Slack notification (if they are enabled)\ntry:\n    if db.slack_notifications_are_enabled():\n        if qc_result != \"Pass\":\n            alert = \"QC \" + qc_result + \": \" + filename\n            slack_bot.send_message(alert)\nexcept:\n    print(\"Failed to send Slack notification.\")\n    traceback.print_exc()\n\nCurrently, this is the simplest component of the pipeline, but posesses a large potential to transform analytical workflows. Future updates will bring more intelligent and informative messages, detailing what went wrong and which component of the LC-MS system may be causing the issue.\nJump to relevant functions:\n\ndb.slack_notifications_are_enabled()\nslack_bot.send_message()\n\n\n\n8. The dashboard is refreshed with QC results\nAfter QC results are written to the database, metadata for the instrument run is updated to trigger a dashboard refresh. The number of samples processed, including the number of passes and fails, is updated using update_sample_counters_for_run().\n\n\nDatabaseFunctions.py\n\ndef update_sample_counters_for_run(instrument_id, run_id, qc_result, latest_sample):\n\n    \"\"\"\n    Increments \"completed\" count, as well as \"pass\" and \"fail\" counts accordingly\n    \"\"\"\n\n    df_instrument_run = get_instrument_run(instrument_id, run_id)\n    completed = df_instrument_run[\"completed\"].astype(int).tolist()[0] + 1\n    passes = df_instrument_run[\"passes\"].astype(int).tolist()[0]\n    fails = df_instrument_run[\"fails\"].astype(int).tolist()[0]\n\n    if qc_result == \"Pass\" or qc_result == \"Warning\":\n        passes = passes + 1\n    elif qc_result == \"Fail\":\n        fails = fails + 1\n\n    db_metadata, connection = connect_to_database(main_database)\n    instrument_runs_table = sa.Table(\"runs\", db_metadata, autoload=True)\n\n    update_status = (\n        sa.update(instrument_runs_table)\n            .where(instrument_runs_table.c.run_id == run_id)\n            .values(\n                completed=completed,\n                passes=passes,\n                fails=fails,\n                latest_sample=latest_sample\n        )\n    )\n\n    connection.execute(update_status)\n    connection.close()\n\nMeanwhile, the web app (served by Dash) stores its copy of the instrument run metadata in the user’s cache. Using a Dash Interval component, a Dash callback is triggered every 15 seconds to compare the run metadata in cache to the run metadata in the database.\n\n\nDashWebApp.py\n\n@app.callback(..., prevent_initial_call=True, suppress_callback_exceptions=True)\ndef load_data(refresh, active_cell, table_data, resources, instrument_id):\n\n    \"\"\"\n    Updates and stores QC results in dcc.Store objects (user's browser session)\n    \"\"\"\n\n    trigger = ctx.triggered_id\n\n    if active_cell:\n        run_id = table_data[active_cell[\"row\"]][\"Run ID\"]\n        status = table_data[active_cell[\"row\"]][\"Status\"]\n\n        # Ensure that refresh does not trigger data parsing if no new samples processed\n        if trigger == \"refresh-interval\":\n            completed_count_in_cache = json.loads(resources)[\"samples_completed\"]\n            actual_completed_count, total = db.get_completed_samples_count(instrument_id, run_id, status)\n\n            if completed_count_in_cache == actual_completed_count:\n                raise PreventUpdate\n\n        # Otherwise, begin route: raw data -> parsed data -> user session cache -> plots\n        return get_qc_results(instrument_id, run_id, status) + (True,)\n\n    else:\n        raise PreventUpdate\n\nWhen a change in the database is detected (via comparing sample counters), all plots in the dashboard are re-populated. The callback continues to check for updates until the end of the instrument run, effectively updating itself in realtime.\nJump to relevant functions:\n\nupdate_sample_counters_for_run()\nget_completed_samples_count()\nload_data()\n\n\n\n\nGoogle Drive sync"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MS-AutoQC",
    "section": "",
    "text": "MS-AutoQC is an all-in-one solution for automated quality control of liquid chromatography-mass spectrometry (LC-MS) data, both during and after data acquisition.\n \nIt offers a fast, straightforward approach to ensure collection of high-quality data, allowing for less time investigating raw data and more time conducting experiments.\nDeveloped at the Mass Spectrometry Platform of CZ Biohub San Francisco, MS-AutoQC provides a host of key features to streamline untargeted metabolomics research, such as:\n\nAutomated and user-defined quality control checks during instrument runs\nRealtime updates on QC fails in the form of Slack or email notifications\nInteractive data visualization of internal standard retention time, m/z, and intensity across samples\nGoogle Drive cloud sync and secure, Google-authenticated access to QC results from any device\n\n\nRequirements\nMS-AutoQC was designed to run on Windows platforms because of its dependency on MSConvert for vendor format data conversion and MS-DIAL for data processing and identification. However, MacOS users can still use MS-AutoQC to monitor / view their instrument run data.\nIn addition, MS-AutoQC requires Python 3.8+ and various Python packages, including Pandas, SQLAlchemy, Plotly, Dash, Bootstrap, Watchdog, Google API, and Slack API. These are installed automatically during setup.\nNote: Installation of Python and various Python packages on MS instrument computers comes at no risk. For extra security and peace of mind, you can opt to install MS-AutoQC in a virtual environment. To learn more, please read the installation guide.\n\n\nInstallation\nInstalling MS-AutoQC is easy. Simply open your Terminal or Command Prompt and type:\npy -m pip install ms-autoqc\nPython dependencies are installed automatically, but dependencies such as MSConvert and MS-DIAL will need to be installed manually. Check out the installation guide for more details.\nIf necessary, you can download and install MS-AutoQC v1.0.0 manually from GitHub – although we strongly recommend using pip!\nPlease keep in mind that MS-AutoQC is still in beta development. If you encounter a bug or issue, please report it by opening an issue on GitHub.\n\n\nSupported Vendors\nMS-AutoQC was designed to be a universal, open-source solution for data quality control. Because MSConvert converts raw acquired data into open mzML format before routing it to the data processing pipeline, the package will work seamlessly with data of all vendor formats.\nHowever, MS-AutoQC has only been tested extensively on Thermo Fisher mass spectrometers and Thermo RAW files. As such, it is expected that there may be bugs / issues with processing data of other vendor formats.\nWe are welcome to collaboration! If you would like to help us comprehensively test support on Agilent / Bruker / Sciex / Waters instruments, please send an email to brian.defelice@czbiohub.org."
  },
  {
    "objectID": "getting-started.html",
    "href": "getting-started.html",
    "title": "Getting Started",
    "section": "",
    "text": "In this section, you can learn how to set up and configure MS-AutoQC for your mass spectrometry instrument."
  },
  {
    "objectID": "getting-started.html#navigation",
    "href": "getting-started.html#navigation",
    "title": "Getting Started",
    "section": "Navigation",
    "text": "Navigation\n\nStart MS-AutoQC\nCreate a new workspace\nConfigure internal standards\nConfigure AutoQC parameters\nSpecify MS-DIAL location\nSetup a new run\nOptional: Configure biological standards\nOptional: Configure MS-DIAL processing parameters\nOptional: Configure Google Drive sync\nOptional: Configure Slack/email notifications"
  },
  {
    "objectID": "getting-started.html#start-ms-autoqc",
    "href": "getting-started.html#start-ms-autoqc",
    "title": "Getting Started",
    "section": "1. Start MS-AutoQC",
    "text": "1. Start MS-AutoQC\nTo launch MS-AutoQC, open a Terminal or Command Prompt window and type:\npy -m start_autoqc"
  },
  {
    "objectID": "getting-started.html#create-a-new-workspace",
    "href": "getting-started.html#create-a-new-workspace",
    "title": "Getting Started",
    "section": "2. Create a new workspace",
    "text": "2. Create a new workspace\nIf you followed the steps in the installation guide correctly, you will be greeted by the following welcome screen:\n\n\n\nWelcome screen\n\n\nPlease select I’m setting up MS-AutoQC on a new instrument. Then, you will be prompted to give your instrument a unique name and select your instrument’s vendor.\n\n\n\nI’m setting up MS-AutoQC on a new instrument\n\n\n\nOptional: Sync with Google Drive\nTBD\nOnce you’re done, click Complete setup to create your workspace. After your workspace loads, it should look something like this:\n\n\n\nBlank workspace"
  },
  {
    "objectID": "getting-started.html#configure-internal-standards",
    "href": "getting-started.html#configure-internal-standards",
    "title": "Getting Started",
    "section": "3. Configure internal standards",
    "text": "3. Configure internal standards\nNow that the workspace has been created, you’re ready to start configuring your chromatography methods and corresponding internal standards. The workflow for adding internal standards is simple:\n\nAdd a chromatography method\nSelect the chromatography and polarity to modify\nAdd an internal standard library\nOptional: Set a different MS-DIAL processing configuration\n\n\n3a. Add a chromatography method\nNavigate to Settings (in the top right corner) > Internal Standards. Once you’re there, it should look something like this:\n\nIn the Manage chromatography methods section at the top, add a new chromatography method by giving it a name and clicking Add method.\n\nIf successful, you should see your new method in the Chromatography methods table.\n\n\n3b. Select the chromatography and polarity to modify\nInternal standards must be configured for both positive and negative mode for each chromatography method.\nLet’s start by selecting the chromatography method you created, and then selecting Positive Mode for the polarity.\n\n\n\n3c. Add an internal standard library\nNow, we can specify our internal standard library. MS-AutoQC accepts identification libraries in either MSP or CSV format.\nIt is important to note that MS-DIAL can only perform MS2 spectral matching using MSP libraries. If you use a CSV library, identification will be performed via m/z and RT matches.\nHere is an example internal standard library in CSV format:\n\n\n\nCommon Name\nMS1 m/z\nRT (min)\n\n\n\n\n1_Methionine_d8\n158.1085398\n7.479\n\n\n1_1_Methylnicotinamide_d3\n141.0975946\n6.217\n\n\n1_Creatinine_d3\n117.0850186\n4.908\n\n\n…\n…\n…\n\n\n1_Lysine d8\n155.1630181\n9.578\n\n\n1_Phenylalanine d8\n174.136469\n6.92\n\n\n1_Hippuric acid d5\n185.0969033\n3.011\n\n\n\nAnd here is one internal standard from a library in MSP format:\nNAME: 1_HippuricAcid_d5\nSCANNUMBER: 1229\nRETENTIONTIME: 3.011485\nPRECURSORMZ: 185.0967\nPRECURSORTYPE: [M+H]+\nIONMODE: Positive\nINTENSITY: 2.157809E+07\nISOTOPE: M + 0\nINCHIKEY:\nSMILES:\nFORMULA:\nNum Peaks: 33\n51.02318    5550\n56.94302    2599\n57.93503    32786\n...\n171.3111    3202\n181.08981   2837\n185.09656   4996\nClick the Browse Files button to browse for your MSP or CSV file, then click the Add MSP to  Positive Mode button.\n\nThat’s it! Now, you can select Negative Mode from the polarity dropdown and add your negative mode internal standards. Once you’re done, your screen should look something like this:"
  },
  {
    "objectID": "getting-started.html#configure-qc-parameters",
    "href": "getting-started.html#configure-qc-parameters",
    "title": "Getting Started",
    "section": "4. Configure QC parameters",
    "text": "4. Configure QC parameters\nOnce you have configured your chromatography methods, you can then navigate to Settings > QC Configurations to define your QC criteria.\n\nMS-AutoQC stores individual parameters in configurations, so that you can configure a specific configuration to fit each chromatography method.\n\nYou can specify these parameters however you’d like, and enable / disable them as needed. To revert a configuration back to the default recommended settings, simply click the Reset default settings button.\nOnce you’re done, don’t forget to click Save changes!"
  },
  {
    "objectID": "getting-started.html#specify-ms-dial-location",
    "href": "getting-started.html#specify-ms-dial-location",
    "title": "Getting Started",
    "section": "5. Specify MS-DIAL location",
    "text": "5. Specify MS-DIAL location\nThe last thing to do is to specify the location of your MS-DIAL v4 download.\nTo do this, navigate to Settings > MS-DIAL Configurations and browse (or enter) the folder path into the MS-DIAL download location field.\nFor example, if the downloaded MS-DIAL files are located in C:\\Users\\eliaslab\\Documents\\MSDIAL, then enter this into the text field and click Save Changes."
  },
  {
    "objectID": "getting-started.html#setup-a-new-qc-job",
    "href": "getting-started.html#setup-a-new-qc-job",
    "title": "Getting Started",
    "section": "6. Setup a new QC job",
    "text": "6. Setup a new QC job\nSetting up a new QC job was designed to be as fast and easy as possible. To get MS-AutoQC monitoring an active instrument run (or QC’ing a completed batch), the user simply needs to enter a few fields of information:\n\nRun ID\nChromatography method\nOptional: Biological standard(s)\nAcquisition sequence file\nOptional: sample metadata\nData acquisition path\n\n\nMS-AutoQC will intelligently validate that everything is in place for it to start working. It does this by:\n\nEnsuring that the run ID is unique so that data is not corrupted\nVerifying that your chromatography method has valid internal standard libraries\nEnsuring that your acquisition sequence contains the required columns\nVerifying that the data acquisition path exists\nValidating biological standard libraries and sample metadata columns\n\nOnce it has validated these fields, the blue button will become enabled and you’re all set to begin."
  },
  {
    "objectID": "getting-started.html#optional-configure-biological-standards",
    "href": "getting-started.html#optional-configure-biological-standards",
    "title": "Getting Started",
    "section": "7. Optional: Configure biological standards",
    "text": "7. Optional: Configure biological standards"
  },
  {
    "objectID": "getting-started.html#optional-configure-ms-dial-processing-parameters",
    "href": "getting-started.html#optional-configure-ms-dial-processing-parameters",
    "title": "Getting Started",
    "section": "8. Optional: Configure MS-DIAL processing parameters",
    "text": "8. Optional: Configure MS-DIAL processing parameters"
  },
  {
    "objectID": "getting-started.html#optional-configure-google-drive-sync",
    "href": "getting-started.html#optional-configure-google-drive-sync",
    "title": "Getting Started",
    "section": "9. Optional: Configure Google Drive sync",
    "text": "9. Optional: Configure Google Drive sync"
  },
  {
    "objectID": "getting-started.html#optional-configure-slackemail-notifications",
    "href": "getting-started.html#optional-configure-slackemail-notifications",
    "title": "Getting Started",
    "section": "10. Optional: Configure Slack/email notifications",
    "text": "10. Optional: Configure Slack/email notifications"
  },
  {
    "objectID": "user-guide.html",
    "href": "user-guide.html",
    "title": "User Guide",
    "section": "",
    "text": "This page offers brief tutorials for usage and configuration of various MS-AutoQC features. Be sure to use the navigation guide on the right (or Ctrl+F) to find what you’re looking for."
  },
  {
    "objectID": "user-guide.html#how-to-set-up-google-drive-sync",
    "href": "user-guide.html#how-to-set-up-google-drive-sync",
    "title": "User Guide",
    "section": "How to set up Google Drive sync",
    "text": "How to set up Google Drive sync\nTo allow access to your workspace from any device, you must first create a project in the Google Cloud Console and generate an OAuth Client ID for your installation of MS-AutoQC.\nThese actions only need to be performed once. Upon completion, any shared user will be able to use the Client ID and Client Secret to sign in to your workspace.\n\n1. Create a project in the Google Cloud Console\nNavigate to the Google Cloud Console. The landing page should look something like this:\n\nChoose Create or select a project, then click New Project.\nName the project MS-AutoQC and click Create.\n\n\n\n2. Configure the OAuth consent screen\nFrom the sidebar, navigate to APIs & Services > OAuth consent screen.\nFor user type, choose Internal and click Create. Fill in the following:\n\nApp name: MS-AutoQC\nUser support email: [email]\nDeveloper contact information: [email]\n\nOnce you’re done, click Save and Continue.\nOn the next screen, select Add or Remove Scopes. Scroll down to the Manually add scopes section and paste in the following:\nhttps://www.googleapis.com/auth/drive\nhttps://www.googleapis.com/auth/gmail.send\nhttps://www.googleapis.com/auth/userinfo.email\n\nClick Add to Table. Then click Update. Then click Save and Continue.\n\n\n3. Generate the OAuth Client ID\nFrom the sidebar, navigate to APIs & Services > Credentials.\nClick the Create Credentials button and select OAuth client ID.\n\nFor application type, choose Desktop application. Name the application MS-AutoQC.\nOnce you’re done, click Create. A dialog window will appear, providing your client ID and client secret.\n\nThat’s it – you’re all set! Copy these and save them somewhere accessible. If you’re here from the Getting Started tutorial, click here to head back and use these credentials to set up or sign in to your workspace."
  },
  {
    "objectID": "faq.html",
    "href": "faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Frequently Asked Questions"
  },
  {
    "objectID": "installation.html",
    "href": "installation.html",
    "title": "Installation",
    "section": "",
    "text": "Installing MS-AutoQC is relatively easy and straightforward. You’ll need to:\nIf you run into trouble or have any questions, please feel free to open a new issue on GitHub. You can also visit the Frequently Asked Questions to see if your issue has been documented already."
  },
  {
    "objectID": "installation.html#important-note-1",
    "href": "installation.html#important-note-1",
    "title": "Installation",
    "section": "Important note",
    "text": "Important note\nAt this point, if you are installing MS-AutoQC only to sign in to your workspace and view the QC dashboard, you can move on to the Getting Started section and learn how to use MS-AutoQC.\nIf you are installing MS-AutoQC on an instrument computer, follow through with installation of MS-DIAL and MSConvert below."
  }
]