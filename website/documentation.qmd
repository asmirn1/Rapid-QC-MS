---
title: "Documentation"
---

This section details the backend data infrastructure and data processing pipeline packaged into MS-AutoQC, as well as some of the structure and logic of the Dash callbacks that serve the frontend app interface.

If you have any questions, concerns, or suggestions about the design of MS-AutoQC, please don't hesitate to contact us at wasim.sandhu@czbiohub.org or brian.defelice@czbiohub.org.

# General workflow
The diagram below gives a broad overview of how MS-AutoQC listens to instrument runs and processes your data safely and securely. To summarize:

1. The user prepares their run sequence and starts an instrument run
2. The user gives MS-AutoQC the sequence file and the data acquisition path

**At this point, the user's work is done.** They can start monitoring their instrument run from the MS-AutoQC dashboard. Now, the MS-AutoQC workflow is initialized.

1. MS-AutoQC starts "listening" to the data acquisition path
2. When the instrument starts collecting sample data, MS-AutoQC starts comparing checksums
3. Once the sample data has been acquired, the processing pipeline is launched
4. MSConvert converts a copy of the raw data file from closed vendor format to open mzML format
6. MS-DIAL processes the mzML file and quantifies internal standards
7. MS-AutoQC performs quality control checks (based on user-defined criteria)
8. QC results are written to the local database and trigger an update to the MS-AutoQC dashboard
9. If there are any QC fails or warnings, the user is notified (if user opted in for notifications)

![MS-AutoQC data processing pipeline](https://user-images.githubusercontent.com/7220175/201808870-ee51397e-c101-4647-9098-5f43acf5e944.png)

The following sections discuss the MS-AutoQC workflow in detail.

### 1. MS-AutoQC starts listening to the data acquisition path
To initialize the workflow, several functions are executed:

- The instrument run is written to the database
- MSP library files are retrieved from the database
- MS-DIAL parameter files are generated for chromatography methods and biological standards
- Filenames are parsed out from the acquisition sequence file

Once this is done, the acquisition path, filenames, and run ID are passed to the acquisition listener, which is started in the background as a subprocess.

**`MS-AutoQC.py`:**
```python
@app.callback(...)
def new_autoqc_job_setup(button_clicks, run_id, instrument_id, chromatography, bio_standards, sequence, metadata, acquisition_path, qc_config_id, job_type):

    """
    This callback initiates the following:
    1. Writing a new instrument run to the database
    2. Generate parameters files for MS-DIAL processing
    3a. Initializing run monitoring at the given directory for an active run, or
    3b. Iterating through and processing data files for a completed run
    """

    # Write a new instrument run to the database
    db.insert_new_run(run_id, instrument_id, chromatography, bio_standards, sequence, metadata, qc_config_id)

    # Get MSPs and generate parameters files for MS-DIAL processing
    for polarity in ["Positive", "Negative"]:

        # Generate parameters files for processing samples
        msp_file_path = db.get_msp_file_path(chromatography, polarity)
        db.generate_msdial_parameters_file(chromatography, polarity, msp_file_path)

        # Generate parameters files for processing each biological standard
        if bio_standards is not None:
            for bio_standard in bio_standards:
                msp_file_path = db.get_msp_file_path(chromatography, polarity, bio_standard)
                db.generate_msdial_parameters_file(chromatography, polarity, msp_file_path, bio_standard)

    # Get filenames from sequence and filter out preblanks, wash, shutdown, etc.
    filenames = db.get_filenames_from_sequence(sequence)["File Name"].astype(str).tolist()

    # If this is for an active run, initialize run monitoring at the given directory
    if job_type == "active":
        listener = subprocess.Popen(["py", "AcquisitionListener.py", acquisition_path, str(filenames), run_id])
        return True, False, False, ""

    # If this is for a completed run, begin iterating through the files and process them
    elif job_type == "completed":
        return False, True, False, json.dumps(filenames)

    # Handle form validation errors
    else:
        return False, False, True, ""
```

**Jump to relevant functions:**
- [`new_autoqc_job_setup()`](https://github.com/czbiohub/MS-AutoQC/blob/main/MS-AutoQC.py#L4498)
- [`db.get_msp_file_path()`](https://github.com/czbiohub/MS-AutoQC/blob/main/DatabaseFunctions.py#L1405)
- [`db.generate_msdial_parameters_file()`](https://github.com/czbiohub/MS-AutoQC/blob/main/DatabaseFunctions.py#L1131)
- [`db.get_filenames_from_sequence()`](https://github.com/czbiohub/MS-AutoQC/blob/main/DatabaseFunctions.py#L472)

### 2. MS-AutoQC compares checksums
Once the acquisition listener has been called, it waits for a file to be created in the data acquisition path.

Upon file creation, `watch_file()` is called. It writes an initial MD5 checksum<sup>1</sup> of the file to the database, and then initializes an indefinite loop.

**`DataAcquisitionEventHandler` class in `AcquisitionListener.py`:**
```python
def watch_file(self, path, filename, extension, check_interval=180):

        """
        Returns True if MD5 checksum on file matches the MD5 checksum written to the database 3 minutes ago.
        Effectively determines whether sample acquisition has been completed.
        """

        # Write initial MD5 checksum to database
        md5_checksum = get_md5(path + filename + "." + extension)
        db.update_md5_checksum(filename, md5_checksum)

        # Watch file indefinitely
        while os.path.exists(path):

            # Wait 3 minutes
            time.sleep(check_interval)

            new_md5 = get_md5(path + filename + "." + extension)
            old_md5 = db.get_md5(filename)

            # If the MD5 checksum after 3 mins is the same as before, file is done acquiring
            if new_md5 == old_md5:
                break
            else:
                db.update_md5_checksum(filename, new_md5)
        
        return True  
```

The loop waits 3 minutes, then computes the file's MD5 checksum again. If the checksums match, the loop breaks and `qc.process_data_file()` is called. If not, the loop repeats.

**`DataAcquisitionEventHandler` class in `AcquisitionListener.py`:**
```python
    def on_created(self, event):

        """
        Listen for data file creation
        """

        # Remove directory path and file extension from filename
        ...

        # Check if file created is in the sequence
        if not event.is_directory and filename in self.filenames:

            # Start watching file until sample acquisition is complete
            sample_acquired = self.watch_file(path, filename, extension)

            # Execute QC processing
            if sample_acquired:
                qc.process_data_file(event.src_path, filename, extension, self.run_id)

            # Terminate listener when the last data file is acquired
            if filename == self.filenames[-1]:
                self.observer.stop()
```

**Jump to relevant functions:**
- [`on_created()`](https://github.com/czbiohub/MS-AutoQC/blob/main/AcquisitionListener.py#L23)
- [`watch_file()`](https://github.com/czbiohub/MS-AutoQC/blob/main/AcquisitionListener.py#L56)
- [`get_md5()`](https://github.com/czbiohub/MS-AutoQC/blob/main/AcquisitionListener.py#L113)
- [`db.get_md5()`](https://github.com/czbiohub/MS-AutoQC/blob/main/DatabaseFunctions.py#L599)
- [`db.update_md5_checksum()`](https://github.com/czbiohub/MS-AutoQC/blob/main/DatabaseFunctions.py#L623)
- [`qc.process_data_file()`](https://github.com/czbiohub/MS-AutoQC/blob/main/AutoQCProcessing.py#L352)

<sup>1</sup><sub>An MD5 checksum is a 32-character serialized string that represents the contents of a file. If two files have the same MD5 checksum, it is highly likely that they are identical files. Computing this checksum is unlikely to corrupt raw data files, or files of any kind for that matter.</sub>

### 3. The processing pipeline is launched
The processing pipeline is a wrapper function called [`qc.process_data_file()`](https://github.com/czbiohub/MS-AutoQC/blob/main/AutoQCProcessing.py#L352), which gets executed when the instrument has finished writing to the data file. It is be described in detail in the upcoming steps.

In preparation, this function retrieves the following information from the database:
- Instrument run ID
- Chromatography method
- List of samples in run
- List of biological standards in run
- MS-DIAL parameters file path
- List of internal standards for chromatography
- List of targeted features for chromatography and biological standard
- MS-DIAL software folder path

It's worth noting that this pipeline was intended to be modular<sup>2</sup>. 

Simply put, the **input** for whatever data processing software is used is expected to be an **mzML file.**

The **output** of that data processing software should be then be a **peak table,** so that calculations and transformations can be made in the succeeding modules.

For the purpose of untargeted metabolomics, data is currently processed by calling the MS-DIAL via the command line.

**Jump to relevant functions:**
- [`db.get_instrument_run()`](https://github.com/czbiohub/MS-AutoQC/blob/main/DatabaseFunctions.py#L575)
- [`db.get_samples_in_run()`](https://github.com/czbiohub/MS-AutoQC/blob/main/DatabaseFunctions.py#L1814)
- [`db.get_parameter_file_path()`](https://github.com/czbiohub/MS-AutoQC/blob/main/DatabaseFunctions.py#L1444)
- [`db.get_targeted_features()`](https://github.com/czbiohub/MS-AutoQC/blob/main/DatabaseFunctions.py#L1530)
- [`db.get_internal_standards()`](https://github.com/czbiohub/MS-AutoQC/blob/main/DatabaseFunctions.py#L1516)
- [`db.get_msdial_directory()`](https://github.com/czbiohub/MS-AutoQC/blob/main/DatabaseFunctions.py#L1468)
- [`run_msconvert()`](https://github.com/czbiohub/MS-AutoQC/blob/main/AutoQCProcessing.py#L125)
- [`run_msdial_processing()`](https://github.com/czbiohub/MS-AutoQC/blob/main/AutoQCProcessing.py#L149)
- [`peak_list_to_dataframe()`](https://github.com/czbiohub/MS-AutoQC/blob/main/AutoQCProcessing.py#L180)
- [`qc_sample()`](https://github.com/czbiohub/MS-AutoQC/blob/main/AutoQCProcessing.py#L206)
- [`db.write_qc_results()`](https://github.com/czbiohub/MS-AutoQC/blob/main/DatabaseFunctions.py#L652)

<sup>2</sup><sub>As development continues, implementation of other data processing software tools is as straightforward as making a function call to that tool (and storing user parameters, of course).</sub>


### 4. MSConvert converts the raw data to mzML format
To ensure that the raw data remains untouched (and therefore uncorrupted) by MS-AutoQC, it is copied<sup>3</sup> to a local app directory, `MS-AutoQC/data`.

A [Docker image of MSConvert](https://hub.docker.com/r/chambm/pwiz-skyline-i-agree-to-the-vendor-licenses) is then called via the command line. After a few seconds, the mzML file will be saved to `MS-AutoQC/data`.

To prevent unnecessary storage, the copy of the original raw data file is deleted.

**`AutoQCProcessing.py`:**
```python
def run_msconvert(path, filename, extension, output_folder):

    """
    Converts data files in closed vendor format to open mzML format
    """

    # Copy original data file to output folder
    shutil.copy2(path + filename + "." + extension, output_folder)

    # Run MSConvert Docker container and allow 5 seconds for conversion
    command = "docker run --rm -e WINEDEBUG=-all -v " \
            + output_folder.replace(" ", "/") \
            + ":/data chambm/pwiz-skyline-i-agree-to-the-vendor-licenses wine msconvert /data/" \
            + filename + "." + extension
    os.system(command)
    time.sleep(3)

    # Delete copy of original data file
    data_file_copy = output_folder + filename + "." + extension
    os.remove(data_file_copy)

    return
```

**Jump to relevant functions:**
- [`run_msconvert()`](https://github.com/czbiohub/MS-AutoQC/blob/main/AutoQCProcessing.py#L125)

<sup>3</sup><sub>Copying is performed using the native Python function [`shutil.copy2()`](https://docs.python.org/3/library/shutil.html#shutil.copy2), and is unlikely to corrupt the raw data file, or files of any kind.</sub>

### 5. MS-DIAL processes the mzML file

```python
def run_msdial_processing(filename, msdial_path, parameter_file, input_folder, output_folder):

    """
    Processes data files using MS-DIAL command line tools
    """

    # Navigate to directory containing MS-DIAL
    home = os.getcwd()
    os.chdir(msdial_path)

    # Run MS-DIAL
    command = "MsdialConsoleApp.exe lcmsdda -i " + input_folder \
              + " -o " + output_folder \
              + " -m " + parameter_file + " -p"
    os.system(command)

    # Clear data file directory for next sample
    for file in os.listdir(input_folder):
        filepath = os.path.join(input_folder, file)
        try:
            shutil.rmtree(filepath)
        except OSError:
            os.remove(filepath)

    # Return to original working directory
    os.chdir(home)

    # Return .msdial file path
    return output_folder + "/" + filename.split(".")[0] + ".msdial"
```

### 6. MS-AutoQC performs quality control checks
```python
def peak_list_to_dataframe(sample_peak_list, internal_standards=None, targeted_features=None):

    """
    Returns DataFrame with m/z, RT, and intensity info for each internal standard in a given sample
    """

    # Convert .msdial file into a DataFrame
    df_peak_list = pd.read_csv(sample_peak_list, sep="\t", engine="python", skip_blank_lines=True)
    df_peak_list.rename(columns={"Title": "Name"}, inplace=True)

    # Get only the m/z, RT, and intensity columns
    df_peak_list = df_peak_list[["Name", "Precursor m/z", "RT (min)", "Height"]]

    # Query only internal standards (or targeted features for biological standard)
    if internal_standards is not None:
        df_peak_list = df_peak_list.loc[df_peak_list["Name"].isin(internal_standards)]
    elif targeted_features is not None:
        df_peak_list = df_peak_list.loc[df_peak_list["Name"].isin(targeted_features)]

    # DataFrame readiness
    df_peak_list.reset_index(drop=True, inplace=True)

    # Return DataFrame
    return df_peak_list
```

### 7. The MS-AutoQC dashboard is refreshed with QC results
To-do...


### 8. The user is notified of QC fails and warnings
To-do...


# Database schema
Data stays in persistence in a local SQLite database. Together, the **database** and **methods directory** – which stores MSP/TXT libraries and MS-DIAL parameter files – comprise a user's MS-AutoQC workspace. A diagram of the database schema is shown below.
![MS-AutoQC database schema](https://user-images.githubusercontent.com/7220175/201223892-a91451a0-c764-44d3-b735-50efd51ffbdb.png)